<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;yoursite.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script><script src="/js/config.js"></script>
<meta name="description" content="对于知道GPS数据,想要得到某个人的频繁涉及的点,传送门">
<meta property="og:type" content="article">
<meta property="og:title" content="聚类分析实践">
<meta property="og:url" content="http://yoursite.com/2021/05/19/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="BlackC">
<meta property="og:description" content="对于知道GPS数据,想要得到某个人的频繁涉及的点,传送门">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-05-19T01:17:06.000Z">
<meta property="article:modified_time" content="2021-05-19T08:54:10.442Z">
<meta property="article:author" content="X&amp;Z">
<meta property="article:tag" content="learn">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/2021/05/19/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;yoursite.com&#x2F;2021&#x2F;05&#x2F;19&#x2F;%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5&#x2F;&quot;,&quot;path&quot;:&quot;2021&#x2F;05&#x2F;19&#x2F;聚类分析实践&#x2F;&quot;,&quot;title&quot;:&quot;聚类分析实践&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>聚类分析实践 | BlackC</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">BlackC</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E6%83%85%E6%8F%90%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">前情提要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mean-Shift"><span class="nav-number">2.1.</span> <span class="nav-text">Mean-Shift</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spectral-Clustering"><span class="nav-number">2.2.</span> <span class="nav-text">Spectral Clustering</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hierarchical-Clustering"><span class="nav-number">2.3.</span> <span class="nav-text">Hierarchical Clustering</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DBSCAN"><span class="nav-number">2.4.</span> <span class="nav-text">DBSCAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Birch"><span class="nav-number">2.5.</span> <span class="nav-text">Birch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GaussianMixtureModel"><span class="nav-number">2.6.</span> <span class="nav-text">GaussianMixtureModel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KMeans"><span class="nav-number">2.7.</span> <span class="nav-text">KMeans</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Affinity-Propagation"><span class="nav-number">2.8.</span> <span class="nav-text">Affinity Propagation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OPTICS"><span class="nav-number">2.9.</span> <span class="nav-text">OPTICS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Clustering-performance-evaluation"><span class="nav-number">2.10.</span> <span class="nav-text">Clustering performance evaluation</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="X&Z"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">X&Z</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">255</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/jxeditor" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jxeditor" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/05/19/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%E5%AE%9E%E8%B7%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="X&Z">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlackC">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          聚类分析实践
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-05-19 09:17:06 / 修改时间：16:54:10" itemprop="dateCreated datePublished" datetime="2021-05-19T09:17:06+08:00">2021-05-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>对于知道GPS数据,想要得到某个人的频繁涉及的点,<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods">传送门</a></p>
</blockquote>
<span id="more"></span>

<h2 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">已有条件,GPS经纬度数据</span><br><span class="line">A,lat,lon</span><br><span class="line">A,lat,lon</span><br><span class="line">A,lat,lon</span><br><span class="line"></span><br><span class="line">最为简单的方式就是,将经纬度转换为geohash值</span><br><span class="line">A,geohash</span><br><span class="line">A,geohash</span><br><span class="line">A,geohash</span><br><span class="line">然后对geohash截取位数,进行分组统计取出现次数的最大值</span><br><span class="line">最后再将geohash转换为经纬度</span><br><span class="line"></span><br><span class="line">高级一点,用聚类算法,将这批数据跑一遍,得出最终收敛的值</span><br><span class="line"></span><br><span class="line"># 注意</span><br><span class="line">在使用pip install时有时候不成功,可以使用conda install</span><br><span class="line">不过注意名称</span><br><span class="line">e.g: </span><br><span class="line">pip install sklearn</span><br><span class="line">conda install scikit-learn</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><h3 id="Mean-Shift"><a href="#Mean-Shift" class="headerlink" title="Mean-Shift"></a>Mean-Shift</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 均值迁移,在数据集中选定一个点,以这个点为圆心,r为半径,画一个圆</span></span><br><span class="line"><span class="comment"># 计算出点到所有点的向量平均值,圆心与向量均值的和为新的圆心</span></span><br><span class="line"><span class="comment"># 迭代整个过程,直到满足一点</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># Mean-Shift</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MeanShift, estimate_bandwidth</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle  <span class="comment">##python自带的迭代器模块</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##产生随机数据的中心</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line"><span class="comment">##产生的数据个数</span></span><br><span class="line">n_samples=<span class="number">100</span></span><br><span class="line"><span class="comment">##生产数据</span></span><br><span class="line">X, _ = make_blobs(n_samples=n_samples, centers= centers, cluster_std=<span class="number">0.6</span>,</span><br><span class="line">                  random_state =<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##带宽(半径),也就是以某个点为核心时的搜索半径</span></span><br><span class="line">bandwidth = estimate_bandwidth(X, quantile=<span class="number">0.2</span>, n_samples=<span class="number">500</span>)</span><br><span class="line"><span class="comment">##设置均值偏移函数</span></span><br><span class="line">ms = MeanShift(bandwidth=bandwidth, bin_seeding=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">##训练数据</span></span><br><span class="line">ms.fit(X)</span><br><span class="line"><span class="comment">##每个点的标签</span></span><br><span class="line">labels = ms.labels_</span><br><span class="line">print(labels)</span><br><span class="line"><span class="comment">##簇中心的点的集合</span></span><br><span class="line">cluster_centers = ms.cluster_centers_</span><br><span class="line">print(<span class="string">&#x27;cluster_centers:&#x27;</span>,cluster_centers)</span><br><span class="line"><span class="comment">##总共的标签分类</span></span><br><span class="line">labels_unique = np.unique(labels)</span><br><span class="line">print(labels_unique)</span><br><span class="line"><span class="comment">##聚簇的个数,即分类的个数</span></span><br><span class="line">n_clusters_ = <span class="built_in">len</span>(labels_unique)</span><br><span class="line">print(<span class="string">&quot;number of estimated clusters : %d&quot;</span> % n_clusters_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##绘图</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.clf()</span><br><span class="line"></span><br><span class="line">colors = cycle(<span class="string">&#x27;bgrcmykbgrcmykbgrcmykbgrcmyk&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters_), colors):</span><br><span class="line">    <span class="comment">##根据lables中的值是否等于k，重新组成一个True、False的数组</span></span><br><span class="line">    my_members = labels == k</span><br><span class="line">    cluster_center = cluster_centers[k]</span><br><span class="line">    <span class="comment">##X[my_members, 0] 取出my_members对应位置为True的值的横坐标</span></span><br><span class="line">    plt.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], col + <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    plt.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">             markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Estimated number of clusters: %d&#x27;</span> % n_clusters_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="Spectral-Clustering"><a href="#Spectral-Clustering" class="headerlink" title="Spectral Clustering"></a>Spectral Clustering</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 谱聚类,基于图论的聚类</span></span><br><span class="line"><span class="comment"># Spectral Clustering</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> spectral_clustering</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle  <span class="comment">##python自带的迭代器模块</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##产生随机数据的中心</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line"><span class="comment">##产生的数据个数</span></span><br><span class="line">n_samples=<span class="number">3000</span></span><br><span class="line"><span class="comment">##生产数据</span></span><br><span class="line">X, lables_true = make_blobs(n_samples=n_samples, centers= centers, cluster_std=<span class="number">0.6</span>, </span><br><span class="line">                  random_state =<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##变换成矩阵，输入必须是对称矩阵</span></span><br><span class="line">metrics_metrix = (-<span class="number">1</span> * metrics.pairwise.pairwise_distances(X)).astype(np.int32)</span><br><span class="line">metrics_metrix += -<span class="number">1</span> * metrics_metrix.<span class="built_in">min</span>()</span><br><span class="line"><span class="comment">##设置谱聚类函数</span></span><br><span class="line">n_clusters_= <span class="number">4</span></span><br><span class="line">lables = spectral_clustering(metrics_metrix,n_clusters=n_clusters_)</span><br><span class="line"></span><br><span class="line"><span class="comment">##绘图</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.clf()</span><br><span class="line"></span><br><span class="line">colors = cycle(<span class="string">&#x27;bgrcmykbgrcmykbgrcmykbgrcmyk&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters_), colors):</span><br><span class="line">    <span class="comment">##根据lables中的值是否等于k，重新组成一个True、False的数组</span></span><br><span class="line">    my_members = lables == k</span><br><span class="line">    <span class="comment">##X[my_members, 0] 取出my_members对应位置为True的值的横坐标</span></span><br><span class="line">    plt.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], col + <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">plt.title(<span class="string">&#x27;Estimated number of clusters: %d&#x27;</span> % n_clusters_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a>Hierarchical Clustering</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 层次聚类,按照某种方法进行层次分类</span></span><br><span class="line"><span class="comment"># Hierarchical Clustering</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AgglomerativeClustering</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle  <span class="comment">##python自带的迭代器模块</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##产生随机数据的中心</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line"><span class="comment">##产生的数据个数</span></span><br><span class="line">n_samples=<span class="number">3000</span></span><br><span class="line"><span class="comment">##生产数据</span></span><br><span class="line">X, lables_true = make_blobs(n_samples=n_samples, centers= centers, cluster_std=<span class="number">0.6</span>, </span><br><span class="line">                  random_state =<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##设置分层聚类函数</span></span><br><span class="line">linkages = [<span class="string">&#x27;ward&#x27;</span>, <span class="string">&#x27;average&#x27;</span>, <span class="string">&#x27;complete&#x27;</span>]</span><br><span class="line">n_clusters_ = <span class="number">3</span></span><br><span class="line">ac = AgglomerativeClustering(linkage=linkages[<span class="number">2</span>],n_clusters = n_clusters_)</span><br><span class="line"><span class="comment">##训练数据</span></span><br><span class="line">ac.fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment">##每个数据的分类</span></span><br><span class="line">lables = ac.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment">##绘图</span></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.clf()</span><br><span class="line"></span><br><span class="line">colors = cycle(<span class="string">&#x27;bgrcmykbgrcmykbgrcmykbgrcmyk&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters_), colors):</span><br><span class="line">    <span class="comment">##根据lables中的值是否等于k，重新组成一个True、False的数组</span></span><br><span class="line">    my_members = lables == k</span><br><span class="line">    <span class="comment">##X[my_members, 0] 取出my_members对应位置为True的值的横坐标</span></span><br><span class="line">    plt.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], col + <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">plt.title(<span class="string">&#x27;Estimated number of clusters: %d&#x27;</span> % n_clusters_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 密度聚类,基于密度的空间聚类</span></span><br><span class="line"><span class="comment"># DBSCAN</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle  <span class="comment">##python自带的迭代器模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment">##产生随机数据的中心</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line"><span class="comment">##产生的数据个数</span></span><br><span class="line">n_samples=<span class="number">750</span></span><br><span class="line"><span class="comment">##生产数据:此实验结果受cluster_std的影响，或者说受eps 和cluster_std差值影响</span></span><br><span class="line">X, lables_true = make_blobs(n_samples=n_samples, centers= centers, cluster_std=<span class="number">0.4</span>, </span><br><span class="line">                  random_state =<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##设置分层聚类函数</span></span><br><span class="line">db = DBSCAN(eps=<span class="number">0.3</span>, min_samples=<span class="number">10</span>)</span><br><span class="line"><span class="comment">##训练数据</span></span><br><span class="line">db.fit(X)</span><br><span class="line"><span class="comment">##初始化一个全是False的bool类型的数组</span></span><br><span class="line">core_samples_mask = np.zeros_like(db.labels_, dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   这里是关键点(针对这行代码：xy = X[class_member_mask &amp; ~core_samples_mask])：</span></span><br><span class="line"><span class="string">   db.core_sample_indices_  表示的是某个点在寻找核心点集合的过程中暂时被标为噪声点的点(即周围点</span></span><br><span class="line"><span class="string">   小于min_samples)，并不是最终的噪声点。在对核心点进行联通的过程中，这部分点会被进行重新归类(即标签</span></span><br><span class="line"><span class="string">   并不会是表示噪声点的-1)，也可也这样理解，这些点不适合做核心点，但是会被包含在某个核心点的范围之内</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">core_samples_mask[db.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##每个数据的分类</span></span><br><span class="line">lables = db.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment">##分类个数：lables中包含-1，表示噪声点</span></span><br><span class="line">n_clusters_ =<span class="built_in">len</span>(np.unique(lables)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> lables <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##绘图</span></span><br><span class="line">unique_labels = <span class="built_in">set</span>(lables)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   1)np.linspace 返回[0,1]之间的len(unique_labels) 个数</span></span><br><span class="line"><span class="string">   2)plt.cm 一个颜色映射模块</span></span><br><span class="line"><span class="string">   3)生成的每个colors包含4个值，分别是rgba</span></span><br><span class="line"><span class="string">   4)其实这行代码的意思就是生成4个可以和光谱对应的颜色值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">colors = plt.cm.Spectral(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">len</span>(unique_labels)))</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.clf()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, colors):</span><br><span class="line">    <span class="comment">##-1表示噪声点,这里的k表示黑色</span></span><br><span class="line">    <span class="keyword">if</span> k == -<span class="number">1</span>:</span><br><span class="line">        col = <span class="string">&#x27;k&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">##生成一个True、False数组，lables == k 的设置成True</span></span><br><span class="line">    class_member_mask = (lables == k)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">##两个数组做&amp;运算，找出即是核心点又等于分类k的值  markeredgecolor=&#x27;k&#x27;,</span></span><br><span class="line">    xy = X[class_member_mask &amp; core_samples_mask]</span><br><span class="line">    plt.plot(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, c=col,markersize=<span class="number">14</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">       1)~优先级最高，按位对core_samples_mask 求反，求出的是噪音点的位置</span></span><br><span class="line"><span class="string">       2)&amp; 于运算之后，求出虽然刚开始是噪音点的位置，但是重新归类却属于k的点</span></span><br><span class="line"><span class="string">       3)对核心分类之后进行的扩展</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    xy = X[class_member_mask &amp; ~core_samples_mask]     </span><br><span class="line">    plt.plot(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, c=col,markersize=<span class="number">6</span>)</span><br><span class="line">    </span><br><span class="line">plt.title(<span class="string">&#x27;Estimated number of clusters: %d&#x27;</span> % n_clusters_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="Birch"><a href="#Birch" class="headerlink" title="Birch"></a>Birch</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过聚类特征(CF)形成一个聚类特征树</span></span><br><span class="line"><span class="comment"># Birch</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> Birch</span><br><span class="line"></span><br><span class="line"><span class="comment"># X为样本特征，Y为样本簇类别， 共1000个样本，每个样本2个特征，共4个簇，簇中心在[-1,-1], [0,0],[1,1], [2,2]</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>, centers=[[-<span class="number">1</span>,-<span class="number">1</span>], [<span class="number">0</span>,<span class="number">0</span>], [<span class="number">1</span>,<span class="number">1</span>], [<span class="number">2</span>,<span class="number">2</span>]], cluster_std=[<span class="number">0.4</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.3</span>], </span><br><span class="line">                  random_state =<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##设置birch函数</span></span><br><span class="line">birch = Birch(n_clusters = <span class="literal">None</span>)</span><br><span class="line"><span class="comment">##训练数据</span></span><br><span class="line">y_pred = birch.fit_predict(X)</span><br><span class="line"><span class="comment">##绘图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="GaussianMixtureModel"><a href="#GaussianMixtureModel" class="headerlink" title="GaussianMixtureModel"></a>GaussianMixtureModel</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 高斯混合,GMM,任意形状的概率分布都可以用多个高斯分布函数去近似</span></span><br><span class="line"><span class="comment"># 通过属于某一类的概率大小来判断最终的归属类别</span></span><br><span class="line"><span class="comment"># GaussianMixtureModel</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"></span><br><span class="line"><span class="comment"># X为样本特征，Y为样本簇类别， 共1000个样本，每个样本2个特征，共4个簇，簇中心在[-1,-1], [0,0],[1,1], [2,2]</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>, centers=[[-<span class="number">1</span>,-<span class="number">1</span>], [<span class="number">0</span>,<span class="number">0</span>], [<span class="number">1</span>,<span class="number">1</span>], [<span class="number">2</span>,<span class="number">2</span>]], cluster_std=[<span class="number">0.4</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.3</span>], </span><br><span class="line">                  random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##设置gmm函数</span></span><br><span class="line">gmm = GaussianMixture(n_components=<span class="number">4</span>, covariance_type=<span class="string">&#x27;full&#x27;</span>).fit(X)</span><br><span class="line"><span class="comment">##训练数据</span></span><br><span class="line">y_pred = gmm.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment">##绘图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="KMeans"><a href="#KMeans" class="headerlink" title="KMeans"></a>KMeans</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># K均值聚类,KMeans和MiniBatchKMeans</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MiniBatchKMeans, KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances_argmin</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">45</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line">n_clusters = <span class="built_in">len</span>(centers)</span><br><span class="line">X, labels_true = make_blobs(n_samples=<span class="number">3000</span>, centers=centers, cluster_std=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 用Kmeans计算聚类</span></span><br><span class="line"></span><br><span class="line">k_means = KMeans(init=<span class="string">&#x27;k-means++&#x27;</span>, n_clusters=<span class="number">3</span>, n_init=<span class="number">10</span>)</span><br><span class="line">t0 = time.time()</span><br><span class="line">k_means.fit(X)</span><br><span class="line">t_batch = time.time() - t0</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 用MiniBatchKMeans计算聚类</span></span><br><span class="line"></span><br><span class="line">mbk = MiniBatchKMeans(init=<span class="string">&#x27;k-means++&#x27;</span>, n_clusters=<span class="number">3</span>, batch_size=batch_size,</span><br><span class="line">                      n_init=<span class="number">10</span>, max_no_improvement=<span class="number">10</span>, verbose=<span class="number">0</span>)</span><br><span class="line">t0 = time.time()</span><br><span class="line">mbk.fit(X)</span><br><span class="line">t_mini_batch = time.time() - t0</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">fig.subplots_adjust(left=<span class="number">0.02</span>, right=<span class="number">0.98</span>, bottom=<span class="number">0.05</span>, top=<span class="number">0.9</span>)</span><br><span class="line">colors = [<span class="string">&#x27;#4EACC5&#x27;</span>, <span class="string">&#x27;#FF9C34&#x27;</span>, <span class="string">&#x27;#4E9A06&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># MiniBatchKMeans和KMeans算法中的同一簇具有相同的颜色</span></span><br><span class="line">k_means_cluster_centers = k_means.cluster_centers_</span><br><span class="line">order = pairwise_distances_argmin(k_means.cluster_centers_,</span><br><span class="line">                                  mbk.cluster_centers_)</span><br><span class="line">mbk_means_cluster_centers = mbk.cluster_centers_[order]</span><br><span class="line"></span><br><span class="line">k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)</span><br><span class="line">mbk_means_labels = pairwise_distances_argmin(X, mbk_means_cluster_centers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># KMeans</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters), colors):</span><br><span class="line">    my_members = k_means_labels == k</span><br><span class="line">    cluster_center = k_means_cluster_centers[k]</span><br><span class="line">    ax.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">            markerfacecolor=col, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    ax.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">            markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;KMeans&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line">plt.text(-<span class="number">3.5</span>, <span class="number">1.8</span>,  <span class="string">&#x27;train time: %.2fs\ninertia: %f&#x27;</span> % (</span><br><span class="line">    t_batch, k_means.inertia_))</span><br><span class="line"></span><br><span class="line"><span class="comment"># MiniBatchKMeans</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters), colors):</span><br><span class="line">    my_members = mbk_means_labels == k</span><br><span class="line">    cluster_center = mbk_means_cluster_centers[k]</span><br><span class="line">    ax.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">            markerfacecolor=col, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    ax.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">            markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;MiniBatchKMeans&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line">plt.text(-<span class="number">3.5</span>, <span class="number">1.8</span>, <span class="string">&#x27;train time: %.2fs\ninertia: %f&#x27;</span> %</span><br><span class="line">         (t_mini_batch, mbk.inertia_))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示不同</span></span><br><span class="line">different = (mbk_means_labels == <span class="number">4</span>)</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">    different += ((k_means_labels == k) != (mbk_means_labels == k))</span><br><span class="line"></span><br><span class="line">identic = np.logical_not(different)</span><br><span class="line">ax.plot(X[identic, <span class="number">0</span>], X[identic, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">        markerfacecolor=<span class="string">&#x27;#bbbbbb&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">ax.plot(X[different, <span class="number">0</span>], X[different, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">        markerfacecolor=<span class="string">&#x27;m&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Difference&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="Affinity-Propagation"><a href="#Affinity-Propagation" class="headerlink" title="Affinity Propagation"></a>Affinity Propagation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AP算法,近邻传播/亲和力传播算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AffinityPropagation</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 样本数据</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line">X, labels_true = make_blobs(n_samples=<span class="number">300</span>, centers=centers, cluster_std=<span class="number">0.5</span>,</span><br><span class="line">                            random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 计算Affinity Propagation</span></span><br><span class="line">af = AffinityPropagation(preference=-<span class="number">50</span>).fit(X)</span><br><span class="line">cluster_centers_indices = af.cluster_centers_indices_</span><br><span class="line">labels = af.labels_</span><br><span class="line"></span><br><span class="line">n_clusters_ = <span class="built_in">len</span>(cluster_centers_indices)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Estimated number of clusters: %d&#x27;</span> % n_clusters_)</span><br><span class="line">print(<span class="string">&quot;Homogeneity: %0.3f&quot;</span> % metrics.homogeneity_score(labels_true, labels))</span><br><span class="line">print(<span class="string">&quot;Completeness: %0.3f&quot;</span> % metrics.completeness_score(labels_true, labels))</span><br><span class="line">print(<span class="string">&quot;V-measure: %0.3f&quot;</span> % metrics.v_measure_score(labels_true, labels))</span><br><span class="line">print(<span class="string">&quot;Adjusted Rand Index: %0.3f&quot;</span></span><br><span class="line">      % metrics.adjusted_rand_score(labels_true, labels))</span><br><span class="line">print(<span class="string">&quot;Adjusted Mutual Information: %0.3f&quot;</span></span><br><span class="line">      % metrics.adjusted_mutual_info_score(labels_true, labels))</span><br><span class="line">print(<span class="string">&quot;Silhouette Coefficient: %0.3f&quot;</span></span><br><span class="line">      % metrics.silhouette_score(X, labels, metric=<span class="string">&#x27;sqeuclidean&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle</span><br><span class="line"></span><br><span class="line">plt.close(<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">plt.clf()</span><br><span class="line"></span><br><span class="line">colors = cycle(<span class="string">&#x27;bgrcmykbgrcmykbgrcmykbgrcmyk&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters_), colors):</span><br><span class="line">    class_members = labels == k</span><br><span class="line">    cluster_center = X[cluster_centers_indices[k]]</span><br><span class="line">    plt.plot(X[class_members, <span class="number">0</span>], X[class_members, <span class="number">1</span>], col + <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    plt.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">             markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">14</span>)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> X[class_members]:</span><br><span class="line">        plt.plot([cluster_center[<span class="number">0</span>], x[<span class="number">0</span>]], [cluster_center[<span class="number">1</span>], x[<span class="number">1</span>]], col)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Estimated number of clusters: %d&#x27;</span> % n_clusters_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="OPTICS"><a href="#OPTICS" class="headerlink" title="OPTICS"></a>OPTICS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以看做DBSCAN的扩展</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS, cluster_optics_dbscan</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate sample data</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">n_points_per_cluster = <span class="number">250</span></span><br><span class="line"></span><br><span class="line">C1 = [-<span class="number">5</span>, -<span class="number">2</span>] + <span class="number">.8</span> * np.random.randn(n_points_per_cluster, <span class="number">2</span>)</span><br><span class="line">C2 = [<span class="number">4</span>, -<span class="number">1</span>] + <span class="number">.1</span> * np.random.randn(n_points_per_cluster, <span class="number">2</span>)</span><br><span class="line">C3 = [<span class="number">1</span>, -<span class="number">2</span>] + <span class="number">.2</span> * np.random.randn(n_points_per_cluster, <span class="number">2</span>)</span><br><span class="line">C4 = [-<span class="number">2</span>, <span class="number">3</span>] + <span class="number">.3</span> * np.random.randn(n_points_per_cluster, <span class="number">2</span>)</span><br><span class="line">C5 = [<span class="number">3</span>, -<span class="number">2</span>] + <span class="number">1.6</span> * np.random.randn(n_points_per_cluster, <span class="number">2</span>)</span><br><span class="line">C6 = [<span class="number">5</span>, <span class="number">6</span>] + <span class="number">2</span> * np.random.randn(n_points_per_cluster, <span class="number">2</span>)</span><br><span class="line">X = np.vstack((C1, C2, C3, C4, C5, C6))</span><br><span class="line"></span><br><span class="line">clust = OPTICS(min_samples=<span class="number">50</span>, xi=<span class="number">.05</span>, min_cluster_size=<span class="number">.05</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the fit</span></span><br><span class="line">clust.fit(X)</span><br><span class="line"></span><br><span class="line">labels_050 = cluster_optics_dbscan(reachability=clust.reachability_,</span><br><span class="line">                                   core_distances=clust.core_distances_,</span><br><span class="line">                                   ordering=clust.ordering_, eps=<span class="number">0.5</span>)</span><br><span class="line">labels_200 = cluster_optics_dbscan(reachability=clust.reachability_,</span><br><span class="line">                                   core_distances=clust.core_distances_,</span><br><span class="line">                                   ordering=clust.ordering_, eps=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = clust.reachability_[clust.ordering_]</span><br><span class="line">labels = clust.labels_[clust.ordering_]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">G = gridspec.GridSpec(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">ax1 = plt.subplot(G[<span class="number">0</span>, :])</span><br><span class="line">ax2 = plt.subplot(G[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">ax3 = plt.subplot(G[<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">ax4 = plt.subplot(G[<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reachability plot</span></span><br><span class="line">colors = [<span class="string">&#x27;g.&#x27;</span>, <span class="string">&#x27;r.&#x27;</span>, <span class="string">&#x27;b.&#x27;</span>, <span class="string">&#x27;y.&#x27;</span>, <span class="string">&#x27;c.&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> klass, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>), colors):</span><br><span class="line">    Xk = space[labels == klass]</span><br><span class="line">    Rk = reachability[labels == klass]</span><br><span class="line">    ax1.plot(Xk, Rk, color, alpha=<span class="number">0.3</span>)</span><br><span class="line">ax1.plot(space[labels == -<span class="number">1</span>], reachability[labels == -<span class="number">1</span>], <span class="string">&#x27;k.&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">ax1.plot(space, np.full_like(space, <span class="number">2.</span>, dtype=<span class="built_in">float</span>), <span class="string">&#x27;k-&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">ax1.plot(space, np.full_like(space, <span class="number">0.5</span>, dtype=<span class="built_in">float</span>), <span class="string">&#x27;k-.&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Reachability (epsilon distance)&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Reachability Plot&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># OPTICS</span></span><br><span class="line">colors = [<span class="string">&#x27;g.&#x27;</span>, <span class="string">&#x27;r.&#x27;</span>, <span class="string">&#x27;b.&#x27;</span>, <span class="string">&#x27;y.&#x27;</span>, <span class="string">&#x27;c.&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> klass, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>), colors):</span><br><span class="line">    Xk = X[clust.labels_ == klass]</span><br><span class="line">    ax2.plot(Xk[:, <span class="number">0</span>], Xk[:, <span class="number">1</span>], color, alpha=<span class="number">0.3</span>)</span><br><span class="line">ax2.plot(X[clust.labels_ == -<span class="number">1</span>, <span class="number">0</span>], X[clust.labels_ == -<span class="number">1</span>, <span class="number">1</span>], <span class="string">&#x27;k+&#x27;</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Automatic Clustering\nOPTICS&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DBSCAN at 0.5</span></span><br><span class="line">colors = [<span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;greenyellow&#x27;</span>, <span class="string">&#x27;olive&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> klass, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">6</span>), colors):</span><br><span class="line">    Xk = X[labels_050 == klass]</span><br><span class="line">    ax3.plot(Xk[:, <span class="number">0</span>], Xk[:, <span class="number">1</span>], color, alpha=<span class="number">0.3</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">ax3.plot(X[labels_050 == -<span class="number">1</span>, <span class="number">0</span>], X[labels_050 == -<span class="number">1</span>, <span class="number">1</span>], <span class="string">&#x27;k+&#x27;</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">ax3.set_title(<span class="string">&#x27;Clustering at 0.5 epsilon cut\nDBSCAN&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DBSCAN at 2.</span></span><br><span class="line">colors = [<span class="string">&#x27;g.&#x27;</span>, <span class="string">&#x27;m.&#x27;</span>, <span class="string">&#x27;y.&#x27;</span>, <span class="string">&#x27;c.&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> klass, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">4</span>), colors):</span><br><span class="line">    Xk = X[labels_200 == klass]</span><br><span class="line">    ax4.plot(Xk[:, <span class="number">0</span>], Xk[:, <span class="number">1</span>], color, alpha=<span class="number">0.3</span>)</span><br><span class="line">ax4.plot(X[labels_200 == -<span class="number">1</span>, <span class="number">0</span>], X[labels_200 == -<span class="number">1</span>, <span class="number">1</span>], <span class="string">&#x27;k+&#x27;</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">ax4.set_title(<span class="string">&#x27;Clustering at 2.0 epsilon cut\nDBSCAN&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="Clustering-performance-evaluation"><a href="#Clustering-performance-evaluation" class="headerlink" title="Clustering performance evaluation"></a>Clustering performance evaluation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 聚类性能评估</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">uniform_labelings_scores</span>(<span class="params">score_func, n_samples, n_clusters_range,</span></span></span><br><span class="line"><span class="function"><span class="params">                             fixed_n_classes=<span class="literal">None</span>, n_runs=<span class="number">5</span>, seed=<span class="number">42</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute score for 2 random uniform cluster labelings.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Both random labelings have the same number of clusters for each value</span></span><br><span class="line"><span class="string">    possible value in ``n_clusters_range``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    When fixed_n_classes is not None the first labeling is considered a ground</span></span><br><span class="line"><span class="string">    truth class assignment with fixed number of classes.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    random_labels = np.random.RandomState(seed).randint</span><br><span class="line">    scores = np.zeros((<span class="built_in">len</span>(n_clusters_range), n_runs))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> fixed_n_classes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        labels_a = random_labels(low=<span class="number">0</span>, high=fixed_n_classes, size=n_samples)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(n_clusters_range):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_runs):</span><br><span class="line">            <span class="keyword">if</span> fixed_n_classes <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                labels_a = random_labels(low=<span class="number">0</span>, high=k, size=n_samples)</span><br><span class="line">            labels_b = random_labels(low=<span class="number">0</span>, high=k, size=n_samples)</span><br><span class="line">            scores[i, j] = score_func(labels_a, labels_b)</span><br><span class="line">    <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ami_score</span>(<span class="params">U, V</span>):</span></span><br><span class="line">    <span class="keyword">return</span> metrics.adjusted_mutual_info_score(U, V)</span><br><span class="line"></span><br><span class="line">score_funcs = [</span><br><span class="line">    metrics.adjusted_rand_score,</span><br><span class="line">    metrics.v_measure_score,</span><br><span class="line">    ami_score,</span><br><span class="line">    metrics.mutual_info_score,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 independent random clusterings with equal cluster number</span></span><br><span class="line"></span><br><span class="line">n_samples = <span class="number">100</span></span><br><span class="line">n_clusters_range = np.linspace(<span class="number">2</span>, n_samples, <span class="number">10</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plots = []</span><br><span class="line">names = []</span><br><span class="line"><span class="keyword">for</span> score_func <span class="keyword">in</span> score_funcs:</span><br><span class="line">    print(<span class="string">&quot;Computing %s for %d values of n_clusters and n_samples=%d&quot;</span></span><br><span class="line">          % (score_func.__name__, <span class="built_in">len</span>(n_clusters_range), n_samples))</span><br><span class="line"></span><br><span class="line">    t0 = time()</span><br><span class="line">    scores = uniform_labelings_scores(score_func, n_samples, n_clusters_range)</span><br><span class="line">    print(<span class="string">&quot;done in %0.3fs&quot;</span> % (time() - t0))</span><br><span class="line">    plots.append(plt.errorbar(</span><br><span class="line">        n_clusters_range, np.median(scores, axis=<span class="number">1</span>), scores.std(axis=<span class="number">1</span>))[<span class="number">0</span>])</span><br><span class="line">    names.append(score_func.__name__)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Clustering measures for 2 random uniform labelings\n&quot;</span></span><br><span class="line">          <span class="string">&quot;with equal number of clusters&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of clusters (Number of samples is fixed to %d)&#x27;</span> % n_samples)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Score value&#x27;</span>)</span><br><span class="line">plt.legend(plots, names)</span><br><span class="line">plt.ylim(bottom=-<span class="number">0.05</span>, top=<span class="number">1.05</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Random labeling with varying n_clusters against ground class labels</span></span><br><span class="line"><span class="comment"># with fixed number of clusters</span></span><br><span class="line"></span><br><span class="line">n_samples = <span class="number">1000</span></span><br><span class="line">n_clusters_range = np.linspace(<span class="number">2</span>, <span class="number">100</span>, <span class="number">10</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">n_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plots = []</span><br><span class="line">names = []</span><br><span class="line"><span class="keyword">for</span> score_func <span class="keyword">in</span> score_funcs:</span><br><span class="line">    print(<span class="string">&quot;Computing %s for %d values of n_clusters and n_samples=%d&quot;</span></span><br><span class="line">          % (score_func.__name__, <span class="built_in">len</span>(n_clusters_range), n_samples))</span><br><span class="line"></span><br><span class="line">    t0 = time()</span><br><span class="line">    scores = uniform_labelings_scores(score_func, n_samples, n_clusters_range,</span><br><span class="line">                                      fixed_n_classes=n_classes)</span><br><span class="line">    print(<span class="string">&quot;done in %0.3fs&quot;</span> % (time() - t0))</span><br><span class="line">    plots.append(plt.errorbar(</span><br><span class="line">        n_clusters_range, scores.mean(axis=<span class="number">1</span>), scores.std(axis=<span class="number">1</span>))[<span class="number">0</span>])</span><br><span class="line">    names.append(score_func.__name__)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Clustering measures for random uniform labeling\n&quot;</span></span><br><span class="line">          <span class="string">&quot;against reference assignment with %d classes&quot;</span> % n_classes)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Number of clusters (Number of samples is fixed to %d)&#x27;</span> % n_samples)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Score value&#x27;</span>)</span><br><span class="line">plt.ylim(bottom=-<span class="number">0.05</span>, top=<span class="number">1.05</span>)</span><br><span class="line">plt.legend(plots, names)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/learn/" rel="tag"># learn</a>
              <a href="/tags/python/" rel="tag"># python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/05/17/%E7%AE%80%E5%8D%95%E7%9A%84FlinkTopN%E7%9A%84%E6%93%8D%E4%BD%9C%E6%BA%90%E7%A0%81%E6%93%8D%E4%BD%9C/" rel="prev" title="简单的FlinkTopN的操作源码操作">
                  <i class="fa fa-chevron-left"></i> 简单的FlinkTopN的操作源码操作
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/05/26/Mac%E9%80%9A%E8%BF%87Brew%E5%AE%89%E8%A3%85%E7%BB%84%E4%BB%B6%E5%87%BA%E7%8E%B0%E7%8E%AF%E5%A2%83%E9%97%AE%E9%A2%98/" rel="next" title="Mac通过Brew安装组件出现环境问题">
                  Mac通过Brew安装组件出现环境问题 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">X&Z</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  





</body>
</html>
