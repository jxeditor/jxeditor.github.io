<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;yoursite.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script><script src="/js/config.js"></script>
<meta name="description" content="介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码系列之十副本管理写入">
<meta property="og:url" content="http://yoursite.com/2020/05/08/Kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%81%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%86%99%E5%85%A5/index.html">
<meta property="og:site_name" content="BlackC">
<meta property="og:description" content="介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-05-08T01:15:54.000Z">
<meta property="article:modified_time" content="2021-03-21T12:33:13.853Z">
<meta property="article:author" content="X&amp;Z">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/2020/05/08/Kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%81%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%86%99%E5%85%A5/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;yoursite.com&#x2F;2020&#x2F;05&#x2F;08&#x2F;Kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%81%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%86%99%E5%85%A5&#x2F;&quot;,&quot;path&quot;:&quot;2020&#x2F;05&#x2F;08&#x2F;Kafka源码系列之十副本管理写入&#x2F;&quot;,&quot;title&quot;:&quot;Kafka源码系列之十副本管理写入&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Kafka源码系列之十副本管理写入 | BlackC</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">BlackC</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Client%E7%AB%AF%E5%8F%91%E9%80%81Produce%E8%AF%B7%E6%B1%82"><span class="nav-number">1.</span> <span class="nav-text">Client端发送Produce请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Server%E7%AB%AF%E5%A4%84%E7%90%86Produce%E8%AF%B7%E6%B1%82"><span class="nav-number">2.</span> <span class="nav-text">Server端处理Produce请求</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#handleProduceRequest"><span class="nav-number">2.1.</span> <span class="nav-text">handleProduceRequest</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ReplicaManager"><span class="nav-number">2.2.</span> <span class="nav-text">ReplicaManager</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#appendRecords"><span class="nav-number">2.2.1.</span> <span class="nav-text">appendRecords</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#appendToLocalLog"><span class="nav-number">2.2.2.</span> <span class="nav-text">appendToLocalLog()</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Partition-appendRecordsToLeader"><span class="nav-number">2.2.3.</span> <span class="nav-text">Partition.appendRecordsToLeader()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E5%B1%82"><span class="nav-number">3.</span> <span class="nav-text">存储层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Log%E5%AF%B9%E8%B1%A1"><span class="nav-number">3.1.</span> <span class="nav-text">Log对象</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5"><span class="nav-number">3.1.1.</span> <span class="nav-text">日志写入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E5%88%86%E6%AE%B5"><span class="nav-number">3.1.2.</span> <span class="nav-text">日志分段</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LogSegment%E5%AF%B9%E8%B1%A1"><span class="nav-number">3.2.</span> <span class="nav-text">LogSegment对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6"><span class="nav-number">3.3.</span> <span class="nav-text">索引文件</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="X&Z"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">X&Z</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">255</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/jxeditor" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jxeditor" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/08/Kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%81%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%86%99%E5%85%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="X&Z">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlackC">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka源码系列之十副本管理写入
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-05-08 09:15:54" itemprop="dateCreated datePublished" datetime="2020-05-08T09:15:54+08:00">2020-05-08</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-03-21 20:33:13" itemprop="dateModified" datetime="2021-03-21T20:33:13+08:00">2021-03-21</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的</p>
</blockquote>
<span id="more"></span>

<h2 id="Client端发送Produce请求"><a href="#Client端发送Produce请求" class="headerlink" title="Client端发送Produce请求"></a>Client端发送Produce请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在第一章有详细描述,Producer是如何向Server发送请求的</span><br><span class="line">主要是在Sender.sendProduceRequests()方法中实现</span><br><span class="line">发送List&lt;ProducerBatch&gt; batches</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Server端处理Produce请求"><a href="#Server端处理Produce请求" class="headerlink" title="Server端处理Produce请求"></a>Server端处理Produce请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在之前的章节里,可以知道Server端Broker在收到Produce请求后</span><br><span class="line">会有一个KafkaApis进行处理,它是Server端处理所有请求的入口</span><br><span class="line">KafkaApis.PRODUCE -&gt; handleProduceRequest()</span><br></pre></td></tr></table></figure>
<h3 id="handleProduceRequest"><a href="#handleProduceRequest" class="headerlink" title="handleProduceRequest"></a>handleProduceRequest</h3><p>整体为,查看topic是否存在,client是否有相应的Describe权限<br>对于已经有Describe权限的topic查看是否有Write权限<br>调用replicaManager.appendRecords()方法向有Write权限的tp追加相应的record</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleProduceRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> produceRequest = request.body[<span class="type">ProduceRequest</span>]</span><br><span class="line">    <span class="keyword">val</span> numBytesAppended = request.header.toStruct.sizeOf + request.sizeOfBodyInBytes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (produceRequest.isTransactional) &#123;</span><br><span class="line">      <span class="comment">// 事务授权失败</span></span><br><span class="line">      <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="type">Resource</span>(<span class="type">TransactionalId</span>, produceRequest.transactionalId, <span class="type">LITERAL</span>))) &#123;</span><br><span class="line">        sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">TRANSACTIONAL_ID_AUTHORIZATION_FAILED</span>.exception)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Note that authorization to a transactionalId implies ProducerId authorization</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 集群授权失败</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (produceRequest.isIdempotent &amp;&amp; !authorize(request.session, <span class="type">IdempotentWrite</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123;</span><br><span class="line">      sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.exception)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 没有Describe权限</span></span><br><span class="line">    <span class="keyword">val</span> unauthorizedTopicResponses = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]()</span><br><span class="line">    <span class="comment">// 不存在</span></span><br><span class="line">    <span class="keyword">val</span> nonExistingTopicResponses = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]()</span><br><span class="line">    <span class="comment">// 有权限</span></span><br><span class="line">    <span class="keyword">val</span> authorizedRequestInfo = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>]()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 进行筛选,判断有没有Write权限</span></span><br><span class="line">    <span class="keyword">for</span> ((topicPartition, memoryRecords) &lt;- produceRequest.partitionRecordsOrFail.asScala) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="type">Resource</span>(<span class="type">Topic</span>, topicPartition.topic, <span class="type">LITERAL</span>)))</span><br><span class="line">        unauthorizedTopicResponses += topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">TOPIC_AUTHORIZATION_FAILED</span>)</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (!metadataCache.contains(topicPartition))</span><br><span class="line">        nonExistingTopicResponses += topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        authorizedRequestInfo += (topicPartition -&gt; memoryRecords)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the callback for sending a produce response</span></span><br><span class="line">    <span class="comment">// 回调函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(responseStatus: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]) &#123;</span><br><span class="line">      <span class="keyword">val</span> mergedResponseStatus = responseStatus ++ unauthorizedTopicResponses ++ nonExistingTopicResponses</span><br><span class="line">      <span class="keyword">var</span> errorInResponse = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">      mergedResponseStatus.foreach &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (status.error != <span class="type">Errors</span>.<span class="type">NONE</span>) &#123;</span><br><span class="line">          errorInResponse = <span class="literal">true</span></span><br><span class="line">          debug(<span class="string">&quot;Produce request with correlation id %d from client %s on partition %s failed due to %s&quot;</span>.format(</span><br><span class="line">            request.header.correlationId,</span><br><span class="line">            request.header.clientId,</span><br><span class="line">            topicPartition,</span><br><span class="line">            status.error.exceptionName))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// When this callback is triggered, the remote API call has completed</span></span><br><span class="line">      request.apiRemoteCompleteTimeNanos = time.nanoseconds</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Record both bandwidth and request quota-specific values and throttle by muting the channel if any of the quotas</span></span><br><span class="line">      <span class="comment">// have been violated. If both quotas have been violated, use the max throttle time between the two quotas. Note</span></span><br><span class="line">      <span class="comment">// that the request quota is not enforced if acks == 0.</span></span><br><span class="line">      <span class="keyword">val</span> bandwidthThrottleTimeMs = quotas.produce.maybeRecordAndGetThrottleTimeMs(request, numBytesAppended, time.milliseconds())</span><br><span class="line">      <span class="keyword">val</span> requestThrottleTimeMs = <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) <span class="number">0</span> <span class="keyword">else</span> quotas.request.maybeRecordAndGetThrottleTimeMs(request)</span><br><span class="line">      <span class="keyword">val</span> maxThrottleTimeMs = <span class="type">Math</span>.max(bandwidthThrottleTimeMs, requestThrottleTimeMs)</span><br><span class="line">      <span class="keyword">if</span> (maxThrottleTimeMs &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (bandwidthThrottleTimeMs &gt; requestThrottleTimeMs) &#123;</span><br><span class="line">          quotas.produce.throttle(request, bandwidthThrottleTimeMs, sendResponse)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          quotas.request.throttle(request, requestThrottleTimeMs, sendResponse)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 立即发送响应,如果进行限制,则channel已经mute</span></span><br><span class="line">      <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 因为设置的ack=0,相当于client会默认发送成功,如果server在处理过程出现错误,会关闭socket连接来间接通知client</span></span><br><span class="line">        <span class="comment">// client会重新刷新meta,重新建立相应的连接</span></span><br><span class="line">        <span class="keyword">if</span> (errorInResponse) &#123;</span><br><span class="line">          <span class="keyword">val</span> exceptionsSummary = mergedResponseStatus.map &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">            topicPartition -&gt; status.error.exceptionName</span><br><span class="line">          &#125;.mkString(<span class="string">&quot;, &quot;</span>)</span><br><span class="line">          info(</span><br><span class="line">            <span class="string">s&quot;Closing connection due to error during produce request with correlation id <span class="subst">$&#123;request.header.correlationId&#125;</span> &quot;</span> +</span><br><span class="line">              <span class="string">s&quot;from client id <span class="subst">$&#123;request.header.clientId&#125;</span> with ack=0\n&quot;</span> +</span><br><span class="line">              <span class="string">s&quot;Topic and partition to exceptions: <span class="subst">$exceptionsSummary</span>&quot;</span></span><br><span class="line">          )</span><br><span class="line">          closeConnection(request, <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava).errorCounts)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// Note that although request throttling is exempt for acks == 0, the channel may be throttled due to</span></span><br><span class="line">          <span class="comment">// bandwidth quota violation.</span></span><br><span class="line">          sendNoOpResponseExemptThrottle(request)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        sendResponse(request, <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava, maxThrottleTimeMs)), <span class="type">None</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">processingStatsCallback</span></span>(processingStats: <span class="type">FetchResponseStats</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      processingStats.foreach &#123; <span class="keyword">case</span> (tp, info) =&gt;</span><br><span class="line">        updateRecordConversionStats(request, tp, info)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (authorizedRequestInfo.isEmpty)</span><br><span class="line">      sendResponseCallback(<span class="type">Map</span>.empty)</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="type">AdminUtils</span>.<span class="type">AdminClientId</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// call the replica manager to append messages to the replicas</span></span><br><span class="line">      <span class="comment">// 追加Record,写入</span></span><br><span class="line">      replicaManager.appendRecords(</span><br><span class="line">        timeout = produceRequest.timeout.toLong,</span><br><span class="line">        requiredAcks = produceRequest.acks,</span><br><span class="line">        internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">        isFromClient = <span class="literal">true</span>,</span><br><span class="line">        entriesPerPartition = authorizedRequestInfo,</span><br><span class="line">        responseCallback = sendResponseCallback,</span><br><span class="line">        recordConversionStatsCallback = processingStatsCallback)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// if the request is put into the purgatory, it will have a held reference and hence cannot be garbage collected;</span></span><br><span class="line">      <span class="comment">// hence we clear its data here in order to let GC reclaim its memory since it is already appended to log</span></span><br><span class="line">      produceRequest.clearPartitionRecords()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="ReplicaManager"><a href="#ReplicaManager" class="headerlink" title="ReplicaManager"></a>ReplicaManager</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">副本管理器,一个副本对应一个Log对象</span><br><span class="line">KafkaServer启动时,会创建ReplicaManager对象</span><br><span class="line">ReplicaManager并不负责具体的日志创建,只是管理Broker上的所有分区</span><br><span class="line">在创建Partition对象时,需要ReplicaManager的LogManager对象</span><br><span class="line">Partition会通过这个LogManager对象为每个Replica创建相应的日志</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 注意replicaManager与logManager的来源</span><br><span class="line">object Partition &#123;</span><br><span class="line">  def apply(topicPartition: TopicPartition,</span><br><span class="line">            time: Time,</span><br><span class="line">            replicaManager: ReplicaManager): Partition &#x3D; &#123;</span><br><span class="line">    new Partition(topicPartition,</span><br><span class="line">      isOffline &#x3D; false,</span><br><span class="line">      replicaLagTimeMaxMs &#x3D; replicaManager.config.replicaLagTimeMaxMs,</span><br><span class="line">      localBrokerId &#x3D; replicaManager.config.brokerId,</span><br><span class="line">      time &#x3D; time,</span><br><span class="line">      replicaManager &#x3D; replicaManager,</span><br><span class="line">      logManager &#x3D; replicaManager.logManager,</span><br><span class="line">      zkClient &#x3D; replicaManager.zkClient)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ReplicaManager与LogManager的对比</span><br><span class="line">LogManager管理Log,由LogSegment组成</span><br><span class="line">ReplicaManager管理Partition,由Replica组成</span><br><span class="line"></span><br><span class="line">replicaManager &#x3D; createReplicaManager(isShuttingDown)</span><br><span class="line">replicaManager.startup()</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 传递了LogManager</span><br><span class="line">protected def createReplicaManager(isShuttingDown: AtomicBoolean): ReplicaManager &#x3D;</span><br><span class="line">    new ReplicaManager(config, metrics, time, zkClient, kafkaScheduler, logManager, isShuttingDown, quotaManagers,</span><br><span class="line">      brokerTopicStats, metadataCache, logDirFailureChannel)</span><br></pre></td></tr></table></figure>
<h4 id="appendRecords"><a href="#appendRecords" class="headerlink" title="appendRecords"></a>appendRecords</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>判断acks设置是否有效(<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>),无效直接返回异常,不再处理</span><br><span class="line"><span class="number">2.</span>有效,调用appendToLocalLog()将records追加到本地对应的<span class="type">Log</span>对象中</span><br><span class="line"><span class="number">3.</span>appendToLocalLog()处理完后,如果发现clients设置的acks=<span class="number">-1</span>,则需要isr的其他副本同步完成才能返回<span class="type">Response</span></span><br><span class="line">    那么就会创建一个<span class="type">DelayedProduce</span>对象,等待isr其他副本进行同步</span><br><span class="line">    否则直接返回追加的结果</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向partition的leader写入数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                    requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                    internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                    isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                    entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                    responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                    delayedProduceLock: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span>,</span><br><span class="line">                    recordConversionStatsCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">RecordConversionStats</span>] =&gt; <span class="type">Unit</span> = _ =&gt; ()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123; <span class="comment">// acks设置有效</span></span><br><span class="line">      <span class="keyword">val</span> sTime = time.milliseconds</span><br><span class="line">      <span class="comment">// 向本地的副本log追加数据</span></span><br><span class="line">      <span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">        isFromClient = isFromClient, entriesPerPartition, requiredAcks)</span><br><span class="line">      debug(<span class="string">&quot;Produce to local log in %d ms&quot;</span>.format(time.milliseconds - sTime))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        topicPartition -&gt;</span><br><span class="line">                <span class="type">ProducePartitionStatus</span>(</span><br><span class="line">                  result.info.lastOffset + <span class="number">1</span>, <span class="comment">// required offset</span></span><br><span class="line">                  <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.error, result.info.firstOffset.getOrElse(<span class="number">-1</span>), result.info.logAppendTime, result.info.logStartOffset)) <span class="comment">// response status</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      recordConversionStatsCallback(localProduceResults.mapValues(_.info.recordConversionStats))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (delayedProduceRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;</span><br><span class="line">        <span class="comment">// 处理ack=-1的情况,需要等到isr的follower都写入成功,才能返回最后结果</span></span><br><span class="line">        <span class="comment">// create delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">        <span class="comment">// 延迟produce请求</span></span><br><span class="line">        <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> producerRequestKeys = entriesPerPartition.keys.map(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line"></span><br><span class="line">        <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory</span></span><br><span class="line">        <span class="comment">// this is because while the delayed produce operation is being created, new</span></span><br><span class="line">        <span class="comment">// requests may arrive and hence make this operation completable.</span></span><br><span class="line">        delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line"></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// we can respond immediately</span></span><br><span class="line">        <span class="keyword">val</span> produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</span><br><span class="line">        <span class="comment">// 通过回调函数直接返回结果</span></span><br><span class="line">        responseCallback(produceResponseStatus)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 返回INVALID_REQUIRED_ACKS错误</span></span><br><span class="line">      <span class="comment">// If required.acks is outside accepted range, something is wrong with the client</span></span><br><span class="line">      <span class="comment">// Just return an error and don&#x27;t handle the request at all</span></span><br><span class="line">      <span class="keyword">val</span> responseStatus = entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, _) =&gt;</span><br><span class="line">        topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">INVALID_REQUIRED_ACKS</span>,</span><br><span class="line">          <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.firstOffset.getOrElse(<span class="number">-1</span>), <span class="type">RecordBatch</span>.<span class="type">NO_TIMESTAMP</span>, <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.logStartOffset)</span><br><span class="line">      &#125;</span><br><span class="line">      responseCallback(responseStatus)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="appendToLocalLog"><a href="#appendToLocalLog" class="headerlink" title="appendToLocalLog()"></a>appendToLocalLog()</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>首先判断要写入的topic是不是kafka内置的topic,内置topic不允许<span class="type">Producer</span>写入</span><br><span class="line"><span class="number">2.</span>查找<span class="type">TP</span>对应的<span class="type">Partition</span>对象,如果在allPartitions中查找到了对应的<span class="type">Partition</span></span><br><span class="line">    直接调用partition.appendRecordsToLeader()追加相应的records</span><br><span class="line">    否则向client抛出异常</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向本地的Replica写入数据</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendToLocalLog</span></span>(internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                               isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                               entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                               requiredAcks: <span class="type">Short</span>): <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">LogAppendResult</span>] = &#123;</span><br><span class="line">    trace(<span class="string">s&quot;Append [<span class="subst">$entriesPerPartition</span>] to local log&quot;</span>)</span><br><span class="line">    entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, records) =&gt;</span><br><span class="line">      <span class="comment">// 遍历要写的所哦呦tp</span></span><br><span class="line">      brokerTopicStats.topicStats(topicPartition.topic).totalProduceRequestRate.mark()</span><br><span class="line">      brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark()</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 不允许向kafka内部使用的topic追加数据</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="type">Topic</span>.isInternal(topicPartition.topic) &amp;&amp; !internalTopicsAllowed) &#123;</span><br><span class="line">        (topicPartition, <span class="type">LogAppendResult</span>(</span><br><span class="line">          <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>,</span><br><span class="line">          <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">InvalidTopicException</span>(<span class="string">s&quot;Cannot append to internal topic <span class="subst">$&#123;topicPartition.topic&#125;</span>&quot;</span>))))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// 查找对应的Partition,并向分区对应的副本写入数据文件</span></span><br><span class="line">          <span class="keyword">val</span> partition = getPartitionOrException(topicPartition, expectLeader = <span class="literal">true</span>)</span><br><span class="line">          <span class="comment">// 追加数据</span></span><br><span class="line">          <span class="keyword">val</span> info = partition.appendRecordsToLeader(records, isFromClient, requiredAcks)</span><br><span class="line">          <span class="keyword">val</span> numAppendedMessages = info.numMessages</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 更新Metrics</span></span><br><span class="line">          brokerTopicStats.topicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes)</span><br><span class="line">          brokerTopicStats.allTopicsStats.bytesInRate.mark(records.sizeInBytes)</span><br><span class="line">          brokerTopicStats.topicStats(topicPartition.topic).messagesInRate.mark(numAppendedMessages)</span><br><span class="line">          brokerTopicStats.allTopicsStats.messagesInRate.mark(numAppendedMessages)</span><br><span class="line"></span><br><span class="line">          trace(<span class="string">s&quot;<span class="subst">$&#123;records.sizeInBytes&#125;</span> written to log <span class="subst">$topicPartition</span> beginning at offset &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;<span class="subst">$&#123;info.firstOffset.getOrElse(-1)&#125;</span> and ending at offset <span class="subst">$&#123;info.lastOffset&#125;</span>&quot;</span>)</span><br><span class="line">          (topicPartition, <span class="type">LogAppendResult</span>(info))</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="comment">// 处理追加过程中的异常</span></span><br><span class="line">          <span class="comment">// <span class="doctag">NOTE:</span> Failed produce requests metric is not incremented for known exceptions</span></span><br><span class="line">          <span class="comment">// it is supposed to indicate un-expected failures of a broker in handling a produce request</span></span><br><span class="line">          <span class="keyword">case</span> e@ (_: <span class="type">UnknownTopicOrPartitionException</span> |</span><br><span class="line">                   _: <span class="type">NotLeaderForPartitionException</span> |</span><br><span class="line">                   _: <span class="type">RecordTooLargeException</span> |</span><br><span class="line">                   _: <span class="type">RecordBatchTooLargeException</span> |</span><br><span class="line">                   _: <span class="type">CorruptRecordException</span> |</span><br><span class="line">                   _: <span class="type">KafkaStorageException</span> |</span><br><span class="line">                   _: <span class="type">InvalidTimestampException</span>) =&gt;</span><br><span class="line">            (topicPartition, <span class="type">LogAppendResult</span>(<span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>, <span class="type">Some</span>(e)))</span><br><span class="line">          <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt;</span><br><span class="line">            <span class="keyword">val</span> logStartOffset = getPartition(topicPartition) <span class="keyword">match</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</span><br><span class="line">                partition.logStartOffset</span><br><span class="line">              <span class="keyword">case</span> _ =&gt;</span><br><span class="line">                <span class="number">-1</span></span><br><span class="line">            &#125;</span><br><span class="line">            brokerTopicStats.topicStats(topicPartition.topic).failedProduceRequestRate.mark()</span><br><span class="line">            brokerTopicStats.allTopicsStats.failedProduceRequestRate.mark()</span><br><span class="line">            error(<span class="string">s&quot;Error processing append operation on partition <span class="subst">$topicPartition</span>&quot;</span>, t)</span><br><span class="line">            (topicPartition, <span class="type">LogAppendResult</span>(<span class="type">LogAppendInfo</span>.unknownLogAppendInfoWithLogStartOffset(logStartOffset), <span class="type">Some</span>(t)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Partition-appendRecordsToLeader"><a href="#Partition-appendRecordsToLeader" class="headerlink" title="Partition.appendRecordsToLeader()"></a>Partition.appendRecordsToLeader()</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据topic的min.isrs配置以及当前这个partition的isr情况判断是否可以写入</span></span><br><span class="line"><span class="comment">// 如果不满足条件,抛出NotEnoughReplicasException</span></span><br><span class="line"><span class="comment">// 满足,调用log.append()向replica追加日志</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecordsToLeader</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>, requiredAcks: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">LogAppendInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      leaderReplicaIfLocal <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt;</span><br><span class="line">          <span class="comment">// 获取对应的Log对象</span></span><br><span class="line">          <span class="keyword">val</span> log = leaderReplica.log.get</span><br><span class="line">          <span class="keyword">val</span> minIsr = log.config.minInSyncReplicas</span><br><span class="line">          <span class="keyword">val</span> inSyncSize = inSyncReplicas.size</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Avoid writing to leader if there are not enough insync replicas to make it safe</span></span><br><span class="line">          <span class="comment">// 如果ack设置为-1,isr数小于设置的min.isr时,会向producer抛出异常</span></span><br><span class="line">          <span class="keyword">if</span> (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotEnoughReplicasException</span>(<span class="string">s&quot;The size of the current ISR <span class="subst">$&#123;inSyncReplicas.map(_.brokerId)&#125;</span> &quot;</span> +</span><br><span class="line">              <span class="string">s&quot;is insufficient to satisfy the min.isr requirement of <span class="subst">$minIsr</span> for partition <span class="subst">$topicPartition</span>&quot;</span>)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 向副本对应的log追加相应的数据</span></span><br><span class="line">          <span class="keyword">val</span> info = log.appendAsLeader(records, leaderEpoch = <span class="keyword">this</span>.leaderEpoch, isFromClient)</span><br><span class="line">          <span class="comment">// probably unblock some follower fetch requests since log end offset has been updated</span></span><br><span class="line">          replicaManager.tryCompleteDelayedFetch(<span class="type">TopicPartitionOperationKey</span>(<span class="keyword">this</span>.topic, <span class="keyword">this</span>.partitionId))</span><br><span class="line">          <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">          <span class="comment">// 判断是否需要增加HW(追加日志后会进行一次判断)</span></span><br><span class="line">          (info, maybeIncrementLeaderHW(leaderReplica))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          <span class="comment">// leader不在本台机器上</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotLeaderForPartitionException</span>(<span class="string">&quot;Leader not local for partition %s on broker %d&quot;</span></span><br><span class="line">            .format(topicPartition, localBrokerId))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">    <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line"></span><br><span class="line">    info</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h2><h3 id="Log对象"><a href="#Log对象" class="headerlink" title="Log对象"></a>Log对象</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">每个<span class="type">Replica</span>都会对应一个<span class="type">Log</span>对象,<span class="type">Log</span>对象是管理当前分区的一个单位</span><br><span class="line">它会包含这个分区的所有<span class="type">Segment</span>文件(包括索引,时间戳索引文件)</span><br><span class="line">提供增删查方法</span><br><span class="line"></span><br><span class="line">nextOffsetMetadata: 下一个偏移量元数据,包括activeSegment的下一条消息的偏移量,该activeSegment的基准偏移量及日志分段的大小</span><br><span class="line">activeSegment: <span class="type">Log</span>管理segments中最新segment,一个<span class="type">Log</span>只会有一个activeSegment,其他的segment已经持久化到磁盘了</span><br><span class="line">logEndOffset: 下一条消息的offset,取自nextOffsetMetadata的offset</span><br><span class="line"></span><br><span class="line"><span class="comment">// 声明为volatile,如果该值被修改,其他使用此变量的线程就可以立刻见到变化后的值,在生产和消费都会使用到这个值</span></span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> nextOffsetMetadata: <span class="type">LogOffsetMetadata</span> = _</span><br><span class="line"><span class="comment">// 下一个偏移量元数据</span></span><br><span class="line"><span class="comment">// 第一个参数: 下一条消息的偏移量</span></span><br><span class="line"><span class="comment">// 第二个参数: 日志分段的基准偏移量</span></span><br><span class="line"><span class="comment">// 第三个参数: 日志分段大小</span></span><br><span class="line">nextOffsetMetadata = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(nextOffset, activeSegment.baseOffset, activeSegment.size)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只会有一个活动的日志分段</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">activeSegment</span> </span>= segments.lastEntry.getValue</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下一条消息的offset,从nextOffsetMetadata获取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logEndOffset</span></span>: <span class="type">Long</span> = nextOffsetMetadata.messageOffset</span><br></pre></td></tr></table></figure>
<h4 id="日志写入"><a href="#日志写入" class="headerlink" title="日志写入"></a>日志写入</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></td><td class="code"><pre><span class="line">analyzeAndValidateRecords(): 对这批要写入的消息进行检测,检查消息的大小以及校验</span><br><span class="line">trimInvalidBytes(): 删除无效消息</span><br><span class="line"><span class="type">LogValidator</span>.validateMessagesAndAssignOffsets(): 设置相应的offset和timestrap</span><br><span class="line">maybeRoll(): 判断是否需要新建一个segment,如果当前segment放不下这批消息的话,需要新建</span><br><span class="line">segment.append(): 向segment添加信息</span><br><span class="line">updateLogEndOffset(): 更新<span class="type">LEO</span></span><br><span class="line">flush(): 刷新磁盘</span><br><span class="line"></span><br><span class="line">时间戳记录有两种</span><br><span class="line">    <span class="type">CreateTime</span>: 默认,创建时间</span><br><span class="line">    <span class="type">LogAppendTime</span>: 添加时间</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向activeSegment追加log,必要的情况下,滚动创建新的segment</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>, assignOffsets: <span class="type">Boolean</span>, leaderEpoch: <span class="type">Int</span>): <span class="type">LogAppendInfo</span> = &#123;</span><br><span class="line">    maybeHandleIOException(<span class="string">s&quot;Error while appending records to <span class="subst">$topicPartition</span> in dir <span class="subst">$&#123;dir.getParent&#125;</span>&quot;</span>) &#123;</span><br><span class="line">      <span class="comment">// 返回这批消息的概要信息,并对其进行校验</span></span><br><span class="line">      <span class="keyword">val</span> appendInfo = analyzeAndValidateRecords(records, isFromClient = isFromClient)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// return if we have no valid messages or if this is a duplicate of the last appended entry</span></span><br><span class="line">      <span class="keyword">if</span> (appendInfo.shallowCount == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> appendInfo</span><br><span class="line"></span><br><span class="line">      <span class="comment">// trim any invalid bytes or partial messages before appending it to the on-disk log</span></span><br><span class="line">      <span class="comment">// 删除无效信息</span></span><br><span class="line">      <span class="keyword">var</span> validRecords = trimInvalidBytes(records, appendInfo)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// they are valid, insert them in the log</span></span><br><span class="line">      lock synchronized &#123;</span><br><span class="line">        checkIfMemoryMappedBufferClosed()</span><br><span class="line">        <span class="keyword">if</span> (assignOffsets) &#123;</span><br><span class="line">          <span class="comment">// assign offsets to the message set</span></span><br><span class="line">          <span class="comment">// 计算这个消息集的起始offset,对offset的操作是一个原子操作</span></span><br><span class="line">          <span class="keyword">val</span> offset = <span class="keyword">new</span> <span class="type">LongRef</span>(nextOffsetMetadata.messageOffset)</span><br><span class="line">          <span class="comment">// 作为消息集的第一个offset</span></span><br><span class="line">          appendInfo.firstOffset = <span class="type">Some</span>(offset.value)</span><br><span class="line">          <span class="comment">// 设置时间戳以server收到的时间戳为准</span></span><br><span class="line">          <span class="keyword">val</span> now = time.milliseconds</span><br><span class="line">          <span class="comment">// 验证消息,并为每条record设置相应的offset和timestrap</span></span><br><span class="line">          <span class="keyword">val</span> validateAndOffsetAssignResult = <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">LogValidator</span>.validateMessagesAndAssignOffsets(validRecords,</span><br><span class="line">              offset,</span><br><span class="line">              time,</span><br><span class="line">              now,</span><br><span class="line">              appendInfo.sourceCodec,</span><br><span class="line">              appendInfo.targetCodec,</span><br><span class="line">              config.compact,</span><br><span class="line">              config.messageFormatVersion.recordVersion.value,</span><br><span class="line">              config.messageTimestampType,</span><br><span class="line">              config.messageTimestampDifferenceMaxMs,</span><br><span class="line">              leaderEpoch,</span><br><span class="line">              isFromClient)</span><br><span class="line">          &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">s&quot;Error validating messages while appending to log <span class="subst">$name</span>&quot;</span>, e)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 返回已经计算好的offset和timestrap的MemoryRecord</span></span><br><span class="line">          validRecords = validateAndOffsetAssignResult.validatedRecords</span><br><span class="line">          appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp</span><br><span class="line">          appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp</span><br><span class="line">          <span class="comment">// 最后一条消息的offset</span></span><br><span class="line">          appendInfo.lastOffset = offset.value - <span class="number">1</span></span><br><span class="line">          appendInfo.recordConversionStats = validateAndOffsetAssignResult.recordConversionStats</span><br><span class="line">          <span class="keyword">if</span> (config.messageTimestampType == <span class="type">TimestampType</span>.<span class="type">LOG_APPEND_TIME</span>)</span><br><span class="line">            appendInfo.logAppendTime = now</span><br><span class="line"></span><br><span class="line">          <span class="comment">// re-validate message sizes if there&#x27;s a possibility that they have changed (due to re-compression or message</span></span><br><span class="line">          <span class="comment">// format conversion)</span></span><br><span class="line">          <span class="comment">// 更新metrics记录</span></span><br><span class="line">          <span class="keyword">if</span> (validateAndOffsetAssignResult.messageSizeMaybeChanged) &#123;</span><br><span class="line">            <span class="keyword">for</span> (batch &lt;- validRecords.batches.asScala) &#123;</span><br><span class="line">              <span class="keyword">if</span> (batch.sizeInBytes &gt; config.maxMessageSize) &#123;</span><br><span class="line">                <span class="comment">// we record the original message set size instead of the trimmed size</span></span><br><span class="line">                <span class="comment">// to be consistent with pre-compression bytesRejectedRate recording</span></span><br><span class="line">                brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class="line">                brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RecordTooLargeException</span>(<span class="string">s&quot;Message batch size is <span class="subst">$&#123;batch.sizeInBytes&#125;</span> bytes in append to&quot;</span> +</span><br><span class="line">                  <span class="string">s&quot;partition <span class="subst">$topicPartition</span> which exceeds the maximum configured size of <span class="subst">$&#123;config.maxMessageSize&#125;</span>.&quot;</span>)</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// we are taking the offsets we are given</span></span><br><span class="line">          <span class="keyword">if</span> (!appendInfo.offsetsMonotonic)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OffsetsOutOfOrderException</span>(<span class="string">s&quot;Out of order offsets found in append to <span class="subst">$topicPartition</span>: &quot;</span> +</span><br><span class="line">                                                 records.records.asScala.map(_.offset))</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (appendInfo.firstOrLastOffsetOfFirstBatch &lt; nextOffsetMetadata.messageOffset) &#123;</span><br><span class="line">            <span class="comment">// we may still be able to recover if the log is empty</span></span><br><span class="line">            <span class="comment">// one example: fetching from log start offset on the leader which is not batch aligned,</span></span><br><span class="line">            <span class="comment">// which may happen as a result of AdminClient#deleteRecords()</span></span><br><span class="line">            <span class="keyword">val</span> firstOffset = appendInfo.firstOffset <span class="keyword">match</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">Some</span>(offset) =&gt; offset</span><br><span class="line">              <span class="keyword">case</span> <span class="type">None</span> =&gt; records.batches.asScala.head.baseOffset()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> firstOrLast = <span class="keyword">if</span> (appendInfo.firstOffset.isDefined) <span class="string">&quot;First offset&quot;</span> <span class="keyword">else</span> <span class="string">&quot;Last offset of the first batch&quot;</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnexpectedAppendOffsetException</span>(</span><br><span class="line">              <span class="string">s&quot;Unexpected offset in append to <span class="subst">$topicPartition</span>. <span class="subst">$firstOrLast</span> &quot;</span> +</span><br><span class="line">              <span class="string">s&quot;<span class="subst">$&#123;appendInfo.firstOrLastOffsetOfFirstBatch&#125;</span> is less than the next offset <span class="subst">$&#123;nextOffsetMetadata.messageOffset&#125;</span>. &quot;</span> +</span><br><span class="line">              <span class="string">s&quot;First 10 offsets in append: <span class="subst">$&#123;records.records.asScala.take(10).map(_.offset)&#125;</span>, last offset in&quot;</span> +</span><br><span class="line">              <span class="string">s&quot; append: <span class="subst">$&#123;appendInfo.lastOffset&#125;</span>. Log start offset = <span class="subst">$logStartOffset</span>&quot;</span>,</span><br><span class="line">              firstOffset, appendInfo.lastOffset)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the epoch cache with the epoch stamped onto the message by the leader</span></span><br><span class="line">        validRecords.batches.asScala.foreach &#123; batch =&gt;</span><br><span class="line">          <span class="keyword">if</span> (batch.magic &gt;= <span class="type">RecordBatch</span>.<span class="type">MAGIC_VALUE_V2</span>)</span><br><span class="line">            _leaderEpochCache.assign(batch.partitionLeaderEpoch, batch.baseOffset)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// check messages set size may be exceed config.segmentSize</span></span><br><span class="line">        <span class="keyword">if</span> (validRecords.sizeInBytes &gt; config.segmentSize) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RecordBatchTooLargeException</span>(<span class="string">s&quot;Message batch size is <span class="subst">$&#123;validRecords.sizeInBytes&#125;</span> bytes in append &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;to partition <span class="subst">$topicPartition</span>, which exceeds the maximum configured segment size of <span class="subst">$&#123;config.segmentSize&#125;</span>.&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// now that we have valid records, offsets assigned, and timestamps updated, we need to</span></span><br><span class="line">        <span class="comment">// validate the idempotent/transactional state of the producers and collect some metadata</span></span><br><span class="line">        <span class="keyword">val</span> (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)</span><br><span class="line">        maybeDuplicate.foreach &#123; duplicate =&gt;</span><br><span class="line">          appendInfo.firstOffset = <span class="type">Some</span>(duplicate.firstOffset)</span><br><span class="line">          appendInfo.lastOffset = duplicate.lastOffset</span><br><span class="line">          appendInfo.logAppendTime = duplicate.timestamp</span><br><span class="line">          appendInfo.logStartOffset = logStartOffset</span><br><span class="line">          <span class="keyword">return</span> appendInfo</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// maybe roll the log if this segment is full</span></span><br><span class="line">        <span class="comment">// 如果当前segment满了,需要重新创建一个segment</span></span><br><span class="line">        <span class="keyword">val</span> segment = maybeRoll(validRecords.sizeInBytes, appendInfo)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> logOffsetMetadata = <span class="type">LogOffsetMetadata</span>(</span><br><span class="line">          messageOffset = appendInfo.firstOrLastOffsetOfFirstBatch,</span><br><span class="line">          segmentBaseOffset = segment.baseOffset,</span><br><span class="line">          relativePositionInSegment = segment.size)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 追加消息到当前segment</span></span><br><span class="line">        segment.append(largestOffset = appendInfo.lastOffset,</span><br><span class="line">          largestTimestamp = appendInfo.maxTimestamp,</span><br><span class="line">          shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,</span><br><span class="line">          records = validRecords)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the producer state</span></span><br><span class="line">        <span class="keyword">for</span> ((_, producerAppendInfo) &lt;- updatedProducers) &#123;</span><br><span class="line">          producerAppendInfo.maybeCacheTxnFirstOffsetMetadata(logOffsetMetadata)</span><br><span class="line">          producerStateManager.update(producerAppendInfo)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the transaction index with the true last stable offset. The last offset visible</span></span><br><span class="line">        <span class="comment">// to consumers using READ_COMMITTED will be limited by this value and the high watermark.</span></span><br><span class="line">        <span class="keyword">for</span> (completedTxn &lt;- completedTxns) &#123;</span><br><span class="line">          <span class="keyword">val</span> lastStableOffset = producerStateManager.completeTxn(completedTxn)</span><br><span class="line">          segment.updateTxnIndex(completedTxn, lastStableOffset)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// always update the last producer id map offset so that the snapshot reflects the current offset</span></span><br><span class="line">        <span class="comment">// even if there isn&#x27;t any idempotent data being written</span></span><br><span class="line">        producerStateManager.updateMapEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// increment the log end offset</span></span><br><span class="line">        <span class="comment">// 修改最新的next_offset</span></span><br><span class="line">        updateLogEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the first unstable offset (which is used to compute LSO)</span></span><br><span class="line">        updateFirstUnstableOffset()</span><br><span class="line"></span><br><span class="line">        trace(<span class="string">s&quot;Appended message set with last offset: <span class="subst">$&#123;appendInfo.lastOffset&#125;</span>, &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;first offset: <span class="subst">$&#123;appendInfo.firstOffset&#125;</span>, &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;next offset: <span class="subst">$&#123;nextOffsetMetadata.messageOffset&#125;</span>, &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;and messages: <span class="subst">$validRecords</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 满足条件的话,刷新磁盘</span></span><br><span class="line">        <span class="keyword">if</span> (unflushedMessages &gt;= config.flushInterval)</span><br><span class="line">          flush()</span><br><span class="line"></span><br><span class="line">        appendInfo</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="日志分段"><a href="#日志分段" class="headerlink" title="日志分段"></a>日志分段</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 判断是否需要创建日志分段,如果不需要,就返回当前分段,需要则返回新创建的日志分段</span><br><span class="line">private def maybeRoll(messagesSize: Int, appendInfo: LogAppendInfo): LogSegment &#x3D; &#123;</span><br><span class="line">    &#x2F;&#x2F; 最新日志分段(活跃日志分段)</span><br><span class="line">    val segment &#x3D; activeSegment</span><br><span class="line">    val now &#x3D; time.milliseconds</span><br><span class="line"></span><br><span class="line">    val maxTimestampInMessages &#x3D; appendInfo.maxTimestamp</span><br><span class="line">    val maxOffsetInMessages &#x3D; appendInfo.lastOffset</span><br><span class="line"></span><br><span class="line">    if (segment.shouldRoll(RollParams(config, appendInfo, messagesSize, now))) &#123;</span><br><span class="line">      debug(s&quot;Rolling new log segment (log_size &#x3D; $&#123;segment.size&#125;&#x2F;$&#123;config.segmentSize&#125;&#125;, &quot; +</span><br><span class="line">        s&quot;offset_index_size &#x3D; $&#123;segment.offsetIndex.entries&#125;&#x2F;$&#123;segment.offsetIndex.maxEntries&#125;, &quot; +</span><br><span class="line">        s&quot;time_index_size &#x3D; $&#123;segment.timeIndex.entries&#125;&#x2F;$&#123;segment.timeIndex.maxEntries&#125;, &quot; +</span><br><span class="line">        s&quot;inactive_time_ms &#x3D; $&#123;segment.timeWaitedForRoll(now, maxTimestampInMessages)&#125;&#x2F;$&#123;config.segmentMs - segment.rollJitterMs&#125;).&quot;)</span><br><span class="line">      appendInfo.firstOffset match &#123;</span><br><span class="line">        &#x2F;&#x2F; 创建新的日志分段</span><br><span class="line">        case Some(firstOffset) &#x3D;&gt; roll(firstOffset)</span><br><span class="line">        case None &#x3D;&gt; roll(maxOffsetInMessages - Integer.MAX_VALUE)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      &#x2F;&#x2F; 使用当前的日志分段</span><br><span class="line">      segment</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; LogSegment</span><br><span class="line">def shouldRoll(rollParams: RollParams): Boolean &#x3D; &#123;</span><br><span class="line">  &#x2F;&#x2F; 距离上次日志分段是否达到了阈值</span><br><span class="line">  val reachedRollMs &#x3D; timeWaitedForRoll(rollParams.now, rollParams.maxTimestampInMessages) &gt; rollParams.maxSegmentMs - rollJitterMs</span><br><span class="line">  &#x2F;&#x2F; 1.文件满了,不足以放下这么大的messageSet</span><br><span class="line">  &#x2F;&#x2F; 2.文件有数据,到了分段的阈值</span><br><span class="line">  &#x2F;&#x2F; 3.索引文件满了</span><br><span class="line">  &#x2F;&#x2F; 4.时间索引文件满了</span><br><span class="line">  &#x2F;&#x2F; 5.最大offset,其相对偏移量超过了正整数的阈值</span><br><span class="line">  size &gt; rollParams.maxSegmentBytes - rollParams.messagesSize ||</span><br><span class="line">    (size &gt; 0 &amp;&amp; reachedRollMs) ||</span><br><span class="line">    offsetIndex.isFull || timeIndex.isFull || !canConvertToRelativeOffset(rollParams.maxOffsetInMessages)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 滚动创建日志,并添加到日志管理的映射表中</span><br><span class="line">def roll(expectedNextOffset: Long &#x3D; 0): LogSegment &#x3D; &#123;</span><br><span class="line">    maybeHandleIOException(s&quot;Error while rolling log segment for $topicPartition in dir $&#123;dir.getParent&#125;&quot;) &#123;</span><br><span class="line">      val start &#x3D; time.hiResClockMs()</span><br><span class="line">      lock synchronized &#123;</span><br><span class="line">        checkIfMemoryMappedBufferClosed()</span><br><span class="line">        &#x2F;&#x2F; 选择最新的offset作为基准偏移量</span><br><span class="line">        val newOffset &#x3D; math.max(expectedNextOffset, logEndOffset)</span><br><span class="line">        &#x2F;&#x2F; 创建数据文件</span><br><span class="line">        val logFile &#x3D; Log.logFile(dir, newOffset)</span><br><span class="line">        &#x2F;&#x2F; 创建offset索引文件</span><br><span class="line">        val offsetIdxFile &#x3D; offsetIndexFile(dir, newOffset)</span><br><span class="line">        &#x2F;&#x2F; 创建时间索引文件</span><br><span class="line">        val timeIdxFile &#x3D; timeIndexFile(dir, newOffset)</span><br><span class="line">        val txnIdxFile &#x3D; transactionIndexFile(dir, newOffset)</span><br><span class="line">        for (file &lt;- List(logFile, offsetIdxFile, timeIdxFile, txnIdxFile) if file.exists) &#123;</span><br><span class="line">          warn(s&quot;Newly rolled segment file $&#123;file.getAbsolutePath&#125; already exists; deleting it first&quot;)</span><br><span class="line">          Files.delete(file.toPath)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Option(segments.lastEntry).foreach(_.getValue.onBecomeInactiveSegment())</span><br><span class="line"></span><br><span class="line">        producerStateManager.updateMapEndOffset(newOffset)</span><br><span class="line">        producerStateManager.takeSnapshot()</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 创建一个segment对象</span><br><span class="line">        val segment &#x3D; LogSegment.open(dir,</span><br><span class="line">          baseOffset &#x3D; newOffset,</span><br><span class="line">          config,</span><br><span class="line">          time &#x3D; time,</span><br><span class="line">          fileAlreadyExists &#x3D; false,</span><br><span class="line">          initFileSize &#x3D; initFileSize,</span><br><span class="line">          preallocate &#x3D; config.preallocate)</span><br><span class="line">        &#x2F;&#x2F; 添加到日志管理中</span><br><span class="line">        val prev &#x3D; addSegment(segment)</span><br><span class="line">        if (prev !&#x3D; null)</span><br><span class="line">          throw new KafkaException(s&quot;Trying to roll a new log segment for topic partition $topicPartition with &quot; +</span><br><span class="line">            s&quot;start offset $newOffset while it already exists.&quot;)</span><br><span class="line">        &#x2F;&#x2F; 更新offset</span><br><span class="line">        updateLogEndOffset(nextOffsetMetadata.messageOffset)</span><br><span class="line">        &#x2F;&#x2F; schedule an asynchronous flush of the old segment</span><br><span class="line">        scheduler.schedule(&quot;flush-log&quot;, () &#x3D;&gt; flush(newOffset), delay &#x3D; 0L)</span><br><span class="line"></span><br><span class="line">        info(s&quot;Rolled new log segment at offset $newOffset in $&#123;time.hiResClockMs() - start&#125; ms.&quot;)</span><br><span class="line"></span><br><span class="line">        segment</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="LogSegment对象"><a href="#LogSegment对象" class="headerlink" title="LogSegment对象"></a>LogSegment对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">真正的日志写入,在LogSegment的append()方法中完成</span><br><span class="line">它会跟Kafka最底层的文件通道,mmap打交道</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 在指定offset处追加msgs,需要的情况下追加相应的索引</span><br><span class="line">@nonthreadsafe</span><br><span class="line">def append(largestOffset: Long,</span><br><span class="line">             largestTimestamp: Long,</span><br><span class="line">             shallowOffsetOfMaxTimestamp: Long,</span><br><span class="line">             records: MemoryRecords): Unit &#x3D; &#123;</span><br><span class="line">    if (records.sizeInBytes &gt; 0) &#123;</span><br><span class="line">      trace(s&quot;Inserting $&#123;records.sizeInBytes&#125; bytes at end offset $largestOffset at position $&#123;log.sizeInBytes&#125; &quot; +</span><br><span class="line">            s&quot;with largest timestamp $largestTimestamp at shallow offset $shallowOffsetOfMaxTimestamp&quot;)</span><br><span class="line">      val physicalPosition &#x3D; log.sizeInBytes()</span><br><span class="line">      if (physicalPosition &#x3D;&#x3D; 0)</span><br><span class="line">        rollingBasedTimestamp &#x3D; Some(largestTimestamp)</span><br><span class="line"></span><br><span class="line">      ensureOffsetInRange(largestOffset)</span><br><span class="line"></span><br><span class="line">      &#x2F;&#x2F; 追加到数据文件</span><br><span class="line">      val appendedBytes &#x3D; log.append(records)</span><br><span class="line">      trace(s&quot;Appended $appendedBytes to $&#123;log.file&#125; at end offset $largestOffset&quot;)</span><br><span class="line">      &#x2F;&#x2F; Update the in memory max timestamp and corresponding offset.</span><br><span class="line">      if (largestTimestamp &gt; maxTimestampSoFar) &#123;</span><br><span class="line">        maxTimestampSoFar &#x3D; largestTimestamp</span><br><span class="line">        offsetOfMaxTimestamp &#x3D; shallowOffsetOfMaxTimestamp</span><br><span class="line">      &#125;</span><br><span class="line">      &#x2F;&#x2F; 判断是否需要追加索引(数据每次都会添加到数据文件中,但不是每次都会添加索引的,间隔indexIntervalBytes 大小才会写入一个索引文件)</span><br><span class="line">      if (bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123;</span><br><span class="line">        &#x2F;&#x2F; 添加索引</span><br><span class="line">        offsetIndex.append(largestOffset, physicalPosition)</span><br><span class="line">        timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)</span><br><span class="line">        bytesSinceLastIndexEntry &#x3D; 0</span><br><span class="line">      &#125;</span><br><span class="line">      bytesSinceLastIndexEntry +&#x3D; records.sizeInBytes</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="索引文件"><a href="#索引文件" class="headerlink" title="索引文件"></a>索引文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">offsetIndex以及timeIndex</span><br><span class="line"></span><br><span class="line">offsetIndex</span><br><span class="line">    采用绝对偏移量+相对偏移量的方式进行存储,每个segment最开始的绝对偏移量也是其基准偏移量</span><br><span class="line">    数据文件每隔一定的大小创建一个索引条目,而不是每条消息会创建索引条目,通过index.interval.bytes来配置</span><br><span class="line">        默认4096,4KB</span><br><span class="line"></span><br><span class="line">好处:</span><br><span class="line">    索引条目稀疏</span><br><span class="line">    索引的相对偏移量占据4个字节,绝对偏移量占据8个字节,物理位置4个字节</span><br><span class="line">        使用相对索引可以将每条索引条目的大小从12字节减少到8字节</span><br><span class="line">    因为偏移量有序的,再读取数据时,可以按照二分查找的方式去快速定位偏移量的位置</span><br><span class="line">    这样的稀疏索引是可以完全放到内存中,加快偏移量的查找</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kafka/" rel="tag"># kafka</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/05/07/Kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B9%9D%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/" rel="prev" title="Kafka源码系列之九日志管理">
                  <i class="fa fa-chevron-left"></i> Kafka源码系列之九日志管理
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/05/08/Kafka%E6%BA%90%E7%A0%81%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%81%E4%B8%80%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E8%AF%BB%E5%8F%96/" rel="next" title="Kafka源码系列之十一副本管理读取">
                  Kafka源码系列之十一副本管理读取 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">X&Z</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  





</body>
</html>
