---
title: 一些出现在业务需求上的小点子
date: 2019-06-04 13:59:01
categories: 大数据
tags: 
    - Spark
---
### 1.如何求一段时间内每天的注册人数,并且实现每一天的统计人数都是之前的注册人数加上当天的注册人数
> Demo数据如下表,时间范围为2019-01-01至2019-01-03,左边为原始数据,右边为聚合

|c_time|uid|-|c_time|sum|
|---|---|---|---|---|
|2019-01-01|10001||2019-01-01|1|
|2019-01-02|10002||2019-01-02|2|
|2019-01-02|10003||2019-01-03|3|
|2019-01-03|10004|
|2019-01-03|10005|
|2019-01-03|10006|

<!-- more -->

> SQL简单实现

```sql
SELECT 
    SUM(IF(c_time = "2019-01-01",sum,0)) AS "1",
    SUM(IF(c_time BETWEEN "2019-01-01" AND "2019-01-02",sum,0)) AS "2",
    SUM(IF(c_time BETWEEN "2019-01-01" AND "2019-01-03",sum,0)) AS "3"
FROM t
然后将行转成列
```

> Spark SQL简单实现

```scala
/** 
思路:
1.利用UDF,将c_time转成list形式
    例如:
        2019-01-01进入UDF,根据endDate转化成List[2019-01-01,2019-01-02,2019-01-03]
2.利用explode方法将List转成多行
3.最终进行groupBy
*/
val beginDate = "2019-01-01"
val endDate = "2019-01-03"
val result = tDF
    .filter(s"c_time >='$beginDate' and c_time < '$endDate'")
    .selectExpr("uid","c_time")
    .groupBy("c_time")
    .agg(count("uid")).as("sum")
    .selectExpr("sum","dateList(c_time) date_list")
    .withColumn("c_time",explode($"date_list"))
    .groupBy("c_time")
    .agg(sum("sum")).as("sum")
```
