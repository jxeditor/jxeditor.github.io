<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<title>
  
    Kafka源码系列之十副本管理写入
  
</title>

<meta name="description" content="介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的">
<meta name="keywords" content="kafka">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码系列之十副本管理写入">
<meta property="og:url" content="http://yoursite.com/2020/05/08/Kafka源码系列之十副本管理写入/index.html">
<meta property="og:site_name" content="BlackC">
<meta property="og:description" content="介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-05-08T04:39:41.242Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka源码系列之十副本管理写入">
<meta name="twitter:description" content="介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的">


  <link rel="alternative" href="/atom.xml" title="BlackC" type="application/atom+xml">



  <link rel="icon" href="/images/favicon.ico">


<link rel="stylesheet" href="/perfect-scrollbar/css/perfect-scrollbar.min.css">
<link rel="stylesheet" href="/styles/main.css">






</head>
<body class="monochrome">
  <div class="mobile-header">
  <button class="sidebar-toggle" type="button">
    <span class="icon-bar"></span>
    <span class="icon-bar"></span>
    <span class="icon-bar"></span>
  </button>
  <a class="title" href="/">BlackC</a>
</div>

  <div class="main-container">
    <div class="sidebar">
  <div class="header">
    <h1 class="title"><a href="/">BlackC</a></h1>
    
    <div class="info">
      <div class="content">
        
        
          <div class="author">X&amp;Z</div>
        
      </div>
      
        <div class="avatar">
          
            <a href="/about"><img src="https://raw.githubusercontent.com/jxeditor/Software/master/Blog/logo.jpg"></a>
          
        </div>
      
    </div>
  </div>
  <div class="body">
    
      
        <ul class="nav">
          
            
              <li class="category-list-container">
                <a href="javascript:;">分类</a>
                <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/搭建/">搭建</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/教程/">教程</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编译/">编译</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编辑器/">编辑器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a><span class="category-list-count">10</span></li></ul>
              </li>
            
          
            
              <li class="tag-list-container">
                <a href="javascript:;">标签</a>
                <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cas/">cas</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cdh/">cdh</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/edit/">edit</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elk/">elk</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flink/">flink</a><span class="tag-list-count">72</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/grafana/">grafana</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hbase/">hbase</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hive/">hive</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/interview/">interview</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/">kafka</a><span class="tag-list-count">27</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kylin/">kylin</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/maven/">maven</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mr/">mr</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neo4j/">neo4j</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/os/">os</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/oss/">oss</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/prometheus/">prometheus</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sbt/">sbt</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/">shell</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a><span class="tag-list-count">15</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tomcat/">tomcat</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tools/">tools</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/xwiki/">xwiki</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zk/">zk</a><span class="tag-list-count">1</span></li></ul>
              </li>
            
          
            
              <li class="archive-list-container">
                <a href="javascript:;">归档</a>
                <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">54</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">80</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a><span class="archive-list-count">17</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/">2017</a><span class="archive-list-count">18</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/">2016</a><span class="archive-list-count">10</span></li></ul>
              </li>
            
          
        </ul>
      
        <ul class="nav">
          
            
              <li>
                <a href="/" title="主页">主页</a>
              </li>
            
          
            
              <li>
                <a href="/archives" title="文章">文章</a>
              </li>
            
          
            
              <li>
                <a href="/about" title="关于">关于</a>
              </li>
            
          
        </ul>
      
        <ul class="nav">
          
            
              <li>
                <a href="https://github.com/denjones/hexo-theme-chan" title="样式" target="_blank" rel="noopener">样式</a>
              </li>
            
          
            
              <li>
                <a href="https://github.com/jxeditor" title="Github" target="_blank" rel="noopener">Github</a>
              </li>
            
          
            
              <li>
                <a href="/atom.xml" title="RSS">RSS</a>
              </li>
            
          
        </ul>
      
    
  </div>
</div>

    <div class="main-content">
      
        <div style="max-width: 1000px">
      
          <article id="post-Kafka源码系列之十副本管理写入" class="article article-type-post">
  
    <h1 class="article-header">
      Kafka源码系列之十副本管理写入
    </h1>
  
  

  <div class="article-info">
    <span class="article-date">
  2020-05-08
</span>

    
	<span class="article-category tagcloud">
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/大数据/">大数据</a></li></ul>
	</span>


    
	<span class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li></ul>
	</span>


  </div>
  <div class="article-entry">
    <blockquote>
<p>介绍Server端接收到Produce请求,是如何进行处理的,处理之后分片是如何产生的</p>
</blockquote>
<a id="more"></a>
<h2 id="Client端发送Produce请求"><a href="#Client端发送Produce请求" class="headerlink" title="Client端发送Produce请求"></a>Client端发送Produce请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在第一章有详细描述,Producer是如何向Server发送请求的</span><br><span class="line">主要是在Sender.sendProduceRequests()方法中实现</span><br><span class="line">发送List&lt;ProducerBatch&gt; batches</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Server端处理Produce请求"><a href="#Server端处理Produce请求" class="headerlink" title="Server端处理Produce请求"></a>Server端处理Produce请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在之前的章节里,可以知道Server端Broker在收到Produce请求后</span><br><span class="line">会有一个KafkaApis进行处理,它是Server端处理所有请求的入口</span><br><span class="line">KafkaApis.PRODUCE -&gt; handleProduceRequest()</span><br></pre></td></tr></table></figure>
<h3 id="handleProduceRequest"><a href="#handleProduceRequest" class="headerlink" title="handleProduceRequest"></a>handleProduceRequest</h3><p>整体为,查看topic是否存在,client是否有相应的Describe权限<br>对于已经有Describe权限的topic查看是否有Write权限<br>调用replicaManager.appendRecords()方法向有Write权限的tp追加相应的record<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleProduceRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="keyword">val</span> produceRequest = request.body[<span class="type">ProduceRequest</span>]</span><br><span class="line">    <span class="keyword">val</span> numBytesAppended = request.header.toStruct.sizeOf + request.sizeOfBodyInBytes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (produceRequest.isTransactional) &#123;</span><br><span class="line">      <span class="comment">// 事务授权失败</span></span><br><span class="line">      <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="type">Resource</span>(<span class="type">TransactionalId</span>, produceRequest.transactionalId, <span class="type">LITERAL</span>))) &#123;</span><br><span class="line">        sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">TRANSACTIONAL_ID_AUTHORIZATION_FAILED</span>.exception)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Note that authorization to a transactionalId implies ProducerId authorization</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 集群授权失败</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (produceRequest.isIdempotent &amp;&amp; !authorize(request.session, <span class="type">IdempotentWrite</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123;</span><br><span class="line">      sendErrorResponseMaybeThrottle(request, <span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.exception)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 没有Describe权限</span></span><br><span class="line">    <span class="keyword">val</span> unauthorizedTopicResponses = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]()</span><br><span class="line">    <span class="comment">// 不存在</span></span><br><span class="line">    <span class="keyword">val</span> nonExistingTopicResponses = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]()</span><br><span class="line">    <span class="comment">// 有权限</span></span><br><span class="line">    <span class="keyword">val</span> authorizedRequestInfo = mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>]()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 进行筛选,判断有没有Write权限</span></span><br><span class="line">    <span class="keyword">for</span> ((topicPartition, memoryRecords) &lt;- produceRequest.partitionRecordsOrFail.asScala) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!authorize(request.session, <span class="type">Write</span>, <span class="type">Resource</span>(<span class="type">Topic</span>, topicPartition.topic, <span class="type">LITERAL</span>)))</span><br><span class="line">        unauthorizedTopicResponses += topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">TOPIC_AUTHORIZATION_FAILED</span>)</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (!metadataCache.contains(topicPartition))</span><br><span class="line">        nonExistingTopicResponses += topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>)</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        authorizedRequestInfo += (topicPartition -&gt; memoryRecords)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the callback for sending a produce response</span></span><br><span class="line">    <span class="comment">// 回调函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sendResponseCallback</span></span>(responseStatus: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>]) &#123;</span><br><span class="line">      <span class="keyword">val</span> mergedResponseStatus = responseStatus ++ unauthorizedTopicResponses ++ nonExistingTopicResponses</span><br><span class="line">      <span class="keyword">var</span> errorInResponse = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">      mergedResponseStatus.foreach &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (status.error != <span class="type">Errors</span>.<span class="type">NONE</span>) &#123;</span><br><span class="line">          errorInResponse = <span class="literal">true</span></span><br><span class="line">          debug(<span class="string">"Produce request with correlation id %d from client %s on partition %s failed due to %s"</span>.format(</span><br><span class="line">            request.header.correlationId,</span><br><span class="line">            request.header.clientId,</span><br><span class="line">            topicPartition,</span><br><span class="line">            status.error.exceptionName))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// When this callback is triggered, the remote API call has completed</span></span><br><span class="line">      request.apiRemoteCompleteTimeNanos = time.nanoseconds</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Record both bandwidth and request quota-specific values and throttle by muting the channel if any of the quotas</span></span><br><span class="line">      <span class="comment">// have been violated. If both quotas have been violated, use the max throttle time between the two quotas. Note</span></span><br><span class="line">      <span class="comment">// that the request quota is not enforced if acks == 0.</span></span><br><span class="line">      <span class="keyword">val</span> bandwidthThrottleTimeMs = quotas.produce.maybeRecordAndGetThrottleTimeMs(request, numBytesAppended, time.milliseconds())</span><br><span class="line">      <span class="keyword">val</span> requestThrottleTimeMs = <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) <span class="number">0</span> <span class="keyword">else</span> quotas.request.maybeRecordAndGetThrottleTimeMs(request)</span><br><span class="line">      <span class="keyword">val</span> maxThrottleTimeMs = <span class="type">Math</span>.max(bandwidthThrottleTimeMs, requestThrottleTimeMs)</span><br><span class="line">      <span class="keyword">if</span> (maxThrottleTimeMs &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (bandwidthThrottleTimeMs &gt; requestThrottleTimeMs) &#123;</span><br><span class="line">          quotas.produce.throttle(request, bandwidthThrottleTimeMs, sendResponse)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          quotas.request.throttle(request, requestThrottleTimeMs, sendResponse)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 立即发送响应,如果进行限制,则channel已经mute</span></span><br><span class="line">      <span class="keyword">if</span> (produceRequest.acks == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 因为设置的ack=0,相当于client会默认发送成功,如果server在处理过程出现错误,会关闭socket连接来间接通知client</span></span><br><span class="line">        <span class="comment">// client会重新刷新meta,重新建立相应的连接</span></span><br><span class="line">        <span class="keyword">if</span> (errorInResponse) &#123;</span><br><span class="line">          <span class="keyword">val</span> exceptionsSummary = mergedResponseStatus.map &#123; <span class="keyword">case</span> (topicPartition, status) =&gt;</span><br><span class="line">            topicPartition -&gt; status.error.exceptionName</span><br><span class="line">          &#125;.mkString(<span class="string">", "</span>)</span><br><span class="line">          info(</span><br><span class="line">            <span class="string">s"Closing connection due to error during produce request with correlation id <span class="subst">$&#123;request.header.correlationId&#125;</span> "</span> +</span><br><span class="line">              <span class="string">s"from client id <span class="subst">$&#123;request.header.clientId&#125;</span> with ack=0\n"</span> +</span><br><span class="line">              <span class="string">s"Topic and partition to exceptions: <span class="subst">$exceptionsSummary</span>"</span></span><br><span class="line">          )</span><br><span class="line">          closeConnection(request, <span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava).errorCounts)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// Note that although request throttling is exempt for acks == 0, the channel may be throttled due to</span></span><br><span class="line">          <span class="comment">// bandwidth quota violation.</span></span><br><span class="line">          sendNoOpResponseExemptThrottle(request)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        sendResponse(request, <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">ProduceResponse</span>(mergedResponseStatus.asJava, maxThrottleTimeMs)), <span class="type">None</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">processingStatsCallback</span></span>(processingStats: <span class="type">FetchResponseStats</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      processingStats.foreach &#123; <span class="keyword">case</span> (tp, info) =&gt;</span><br><span class="line">        updateRecordConversionStats(request, tp, info)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (authorizedRequestInfo.isEmpty)</span><br><span class="line">      sendResponseCallback(<span class="type">Map</span>.empty)</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> internalTopicsAllowed = request.header.clientId == <span class="type">AdminUtils</span>.<span class="type">AdminClientId</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// call the replica manager to append messages to the replicas</span></span><br><span class="line">      <span class="comment">// 追加Record,写入</span></span><br><span class="line">      replicaManager.appendRecords(</span><br><span class="line">        timeout = produceRequest.timeout.toLong,</span><br><span class="line">        requiredAcks = produceRequest.acks,</span><br><span class="line">        internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">        isFromClient = <span class="literal">true</span>,</span><br><span class="line">        entriesPerPartition = authorizedRequestInfo,</span><br><span class="line">        responseCallback = sendResponseCallback,</span><br><span class="line">        recordConversionStatsCallback = processingStatsCallback)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// if the request is put into the purgatory, it will have a held reference and hence cannot be garbage collected;</span></span><br><span class="line">      <span class="comment">// hence we clear its data here in order to let GC reclaim its memory since it is already appended to log</span></span><br><span class="line">      produceRequest.clearPartitionRecords()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="ReplicaManager"><a href="#ReplicaManager" class="headerlink" title="ReplicaManager"></a>ReplicaManager</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">副本管理器,一个副本对应一个Log对象</span><br><span class="line">KafkaServer启动时,会创建ReplicaManager对象</span><br><span class="line">ReplicaManager并不负责具体的日志创建,只是管理Broker上的所有分区</span><br><span class="line">在创建Partition对象时,需要ReplicaManager的LogManager对象</span><br><span class="line">Partition会通过这个LogManager对象为每个Replica创建相应的日志</span><br><span class="line"></span><br><span class="line">// 注意replicaManager与logManager的来源</span><br><span class="line">object Partition &#123;</span><br><span class="line">  def apply(topicPartition: TopicPartition,</span><br><span class="line">            time: Time,</span><br><span class="line">            replicaManager: ReplicaManager): Partition = &#123;</span><br><span class="line">    new Partition(topicPartition,</span><br><span class="line">      isOffline = false,</span><br><span class="line">      replicaLagTimeMaxMs = replicaManager.config.replicaLagTimeMaxMs,</span><br><span class="line">      localBrokerId = replicaManager.config.brokerId,</span><br><span class="line">      time = time,</span><br><span class="line">      replicaManager = replicaManager,</span><br><span class="line">      logManager = replicaManager.logManager,</span><br><span class="line">      zkClient = replicaManager.zkClient)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ReplicaManager与LogManager的对比</span><br><span class="line">LogManager管理Log,由LogSegment组成</span><br><span class="line">ReplicaManager管理Partition,由Replica组成</span><br><span class="line"></span><br><span class="line">replicaManager = createReplicaManager(isShuttingDown)</span><br><span class="line">replicaManager.startup()</span><br><span class="line"></span><br><span class="line">// 传递了LogManager</span><br><span class="line">protected def createReplicaManager(isShuttingDown: AtomicBoolean): ReplicaManager =</span><br><span class="line">    new ReplicaManager(config, metrics, time, zkClient, kafkaScheduler, logManager, isShuttingDown, quotaManagers,</span><br><span class="line">      brokerTopicStats, metadataCache, logDirFailureChannel)</span><br></pre></td></tr></table></figure>
<h4 id="appendRecords"><a href="#appendRecords" class="headerlink" title="appendRecords"></a>appendRecords</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>判断acks设置是否有效(<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>),无效直接返回异常,不再处理</span><br><span class="line"><span class="number">2.</span>有效,调用appendToLocalLog()将records追加到本地对应的<span class="type">Log</span>对象中</span><br><span class="line"><span class="number">3.</span>appendToLocalLog()处理完后,如果发现clients设置的acks=<span class="number">-1</span>,则需要isr的其他副本同步完成才能返回<span class="type">Response</span></span><br><span class="line">    那么就会创建一个<span class="type">DelayedProduce</span>对象,等待isr其他副本进行同步</span><br><span class="line">    否则直接返回追加的结果</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向partition的leader写入数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                    requiredAcks: <span class="type">Short</span>,</span><br><span class="line">                    internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                    isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                    entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                    responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                    delayedProduceLock: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span>,</span><br><span class="line">                    recordConversionStatsCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">RecordConversionStats</span>] =&gt; <span class="type">Unit</span> = _ =&gt; ()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isValidRequiredAcks(requiredAcks)) &#123; <span class="comment">// acks设置有效</span></span><br><span class="line">      <span class="keyword">val</span> sTime = time.milliseconds</span><br><span class="line">      <span class="comment">// 向本地的副本log追加数据</span></span><br><span class="line">      <span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">        isFromClient = isFromClient, entriesPerPartition, requiredAcks)</span><br><span class="line">      debug(<span class="string">"Produce to local log in %d ms"</span>.format(time.milliseconds - sTime))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">        topicPartition -&gt;</span><br><span class="line">                <span class="type">ProducePartitionStatus</span>(</span><br><span class="line">                  result.info.lastOffset + <span class="number">1</span>, <span class="comment">// required offset</span></span><br><span class="line">                  <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.error, result.info.firstOffset.getOrElse(<span class="number">-1</span>), result.info.logAppendTime, result.info.logStartOffset)) <span class="comment">// response status</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      recordConversionStatsCallback(localProduceResults.mapValues(_.info.recordConversionStats))</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (delayedProduceRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;</span><br><span class="line">        <span class="comment">// 处理ack=-1的情况,需要等到isr的follower都写入成功,才能返回最后结果</span></span><br><span class="line">        <span class="comment">// create delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">        <span class="comment">// 延迟produce请求</span></span><br><span class="line">        <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create a list of (topic, partition) pairs to use as keys for this delayed produce operation</span></span><br><span class="line">        <span class="keyword">val</span> producerRequestKeys = entriesPerPartition.keys.map(<span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line"></span><br><span class="line">        <span class="comment">// try to complete the request immediately, otherwise put it into the purgatory</span></span><br><span class="line">        <span class="comment">// this is because while the delayed produce operation is being created, new</span></span><br><span class="line">        <span class="comment">// requests may arrive and hence make this operation completable.</span></span><br><span class="line">        delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line"></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// we can respond immediately</span></span><br><span class="line">        <span class="keyword">val</span> produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)</span><br><span class="line">        <span class="comment">// 通过回调函数直接返回结果</span></span><br><span class="line">        responseCallback(produceResponseStatus)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 返回INVALID_REQUIRED_ACKS错误</span></span><br><span class="line">      <span class="comment">// If required.acks is outside accepted range, something is wrong with the client</span></span><br><span class="line">      <span class="comment">// Just return an error and don't handle the request at all</span></span><br><span class="line">      <span class="keyword">val</span> responseStatus = entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, _) =&gt;</span><br><span class="line">        topicPartition -&gt; <span class="keyword">new</span> <span class="type">PartitionResponse</span>(<span class="type">Errors</span>.<span class="type">INVALID_REQUIRED_ACKS</span>,</span><br><span class="line">          <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.firstOffset.getOrElse(<span class="number">-1</span>), <span class="type">RecordBatch</span>.<span class="type">NO_TIMESTAMP</span>, <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>.logStartOffset)</span><br><span class="line">      &#125;</span><br><span class="line">      responseCallback(responseStatus)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="appendToLocalLog"><a href="#appendToLocalLog" class="headerlink" title="appendToLocalLog()"></a>appendToLocalLog()</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>首先判断要写入的topic是不是kafka内置的topic,内置topic不允许<span class="type">Producer</span>写入</span><br><span class="line"><span class="number">2.</span>查找<span class="type">TP</span>对应的<span class="type">Partition</span>对象,如果在allPartitions中查找到了对应的<span class="type">Partition</span></span><br><span class="line">    直接调用partition.appendRecordsToLeader()追加相应的records</span><br><span class="line">    否则向client抛出异常</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向本地的Replica写入数据</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">appendToLocalLog</span></span>(internalTopicsAllowed: <span class="type">Boolean</span>,</span><br><span class="line">                               isFromClient: <span class="type">Boolean</span>,</span><br><span class="line">                               entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>],</span><br><span class="line">                               requiredAcks: <span class="type">Short</span>): <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">LogAppendResult</span>] = &#123;</span><br><span class="line">    trace(<span class="string">s"Append [<span class="subst">$entriesPerPartition</span>] to local log"</span>)</span><br><span class="line">    entriesPerPartition.map &#123; <span class="keyword">case</span> (topicPartition, records) =&gt;</span><br><span class="line">      <span class="comment">// 遍历要写的所哦呦tp</span></span><br><span class="line">      brokerTopicStats.topicStats(topicPartition.topic).totalProduceRequestRate.mark()</span><br><span class="line">      brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark()</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 不允许向kafka内部使用的topic追加数据</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="type">Topic</span>.isInternal(topicPartition.topic) &amp;&amp; !internalTopicsAllowed) &#123;</span><br><span class="line">        (topicPartition, <span class="type">LogAppendResult</span>(</span><br><span class="line">          <span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>,</span><br><span class="line">          <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">InvalidTopicException</span>(<span class="string">s"Cannot append to internal topic <span class="subst">$&#123;topicPartition.topic&#125;</span>"</span>))))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// 查找对应的Partition,并向分区对应的副本写入数据文件</span></span><br><span class="line">          <span class="keyword">val</span> partition = getPartitionOrException(topicPartition, expectLeader = <span class="literal">true</span>)</span><br><span class="line">          <span class="comment">// 追加数据</span></span><br><span class="line">          <span class="keyword">val</span> info = partition.appendRecordsToLeader(records, isFromClient, requiredAcks)</span><br><span class="line">          <span class="keyword">val</span> numAppendedMessages = info.numMessages</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 更新Metrics</span></span><br><span class="line">          brokerTopicStats.topicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes)</span><br><span class="line">          brokerTopicStats.allTopicsStats.bytesInRate.mark(records.sizeInBytes)</span><br><span class="line">          brokerTopicStats.topicStats(topicPartition.topic).messagesInRate.mark(numAppendedMessages)</span><br><span class="line">          brokerTopicStats.allTopicsStats.messagesInRate.mark(numAppendedMessages)</span><br><span class="line"></span><br><span class="line">          trace(<span class="string">s"<span class="subst">$&#123;records.sizeInBytes&#125;</span> written to log <span class="subst">$topicPartition</span> beginning at offset "</span> +</span><br><span class="line">            <span class="string">s"<span class="subst">$&#123;info.firstOffset.getOrElse(-1)&#125;</span> and ending at offset <span class="subst">$&#123;info.lastOffset&#125;</span>"</span>)</span><br><span class="line">          (topicPartition, <span class="type">LogAppendResult</span>(info))</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="comment">// 处理追加过程中的异常</span></span><br><span class="line">          <span class="comment">// <span class="doctag">NOTE:</span> Failed produce requests metric is not incremented for known exceptions</span></span><br><span class="line">          <span class="comment">// it is supposed to indicate un-expected failures of a broker in handling a produce request</span></span><br><span class="line">          <span class="keyword">case</span> e@ (_: <span class="type">UnknownTopicOrPartitionException</span> |</span><br><span class="line">                   _: <span class="type">NotLeaderForPartitionException</span> |</span><br><span class="line">                   _: <span class="type">RecordTooLargeException</span> |</span><br><span class="line">                   _: <span class="type">RecordBatchTooLargeException</span> |</span><br><span class="line">                   _: <span class="type">CorruptRecordException</span> |</span><br><span class="line">                   _: <span class="type">KafkaStorageException</span> |</span><br><span class="line">                   _: <span class="type">InvalidTimestampException</span>) =&gt;</span><br><span class="line">            (topicPartition, <span class="type">LogAppendResult</span>(<span class="type">LogAppendInfo</span>.<span class="type">UnknownLogAppendInfo</span>, <span class="type">Some</span>(e)))</span><br><span class="line">          <span class="keyword">case</span> t: <span class="type">Throwable</span> =&gt;</span><br><span class="line">            <span class="keyword">val</span> logStartOffset = getPartition(topicPartition) <span class="keyword">match</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">Some</span>(partition) =&gt;</span><br><span class="line">                partition.logStartOffset</span><br><span class="line">              <span class="keyword">case</span> _ =&gt;</span><br><span class="line">                <span class="number">-1</span></span><br><span class="line">            &#125;</span><br><span class="line">            brokerTopicStats.topicStats(topicPartition.topic).failedProduceRequestRate.mark()</span><br><span class="line">            brokerTopicStats.allTopicsStats.failedProduceRequestRate.mark()</span><br><span class="line">            error(<span class="string">s"Error processing append operation on partition <span class="subst">$topicPartition</span>"</span>, t)</span><br><span class="line">            (topicPartition, <span class="type">LogAppendResult</span>(<span class="type">LogAppendInfo</span>.unknownLogAppendInfoWithLogStartOffset(logStartOffset), <span class="type">Some</span>(t)))</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Partition-appendRecordsToLeader"><a href="#Partition-appendRecordsToLeader" class="headerlink" title="Partition.appendRecordsToLeader()"></a>Partition.appendRecordsToLeader()</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据topic的min.isrs配置以及当前这个partition的isr情况判断是否可以写入</span></span><br><span class="line"><span class="comment">// 如果不满足条件,抛出NotEnoughReplicasException</span></span><br><span class="line"><span class="comment">// 满足,调用log.append()向replica追加日志</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecordsToLeader</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>, requiredAcks: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">LogAppendInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      leaderReplicaIfLocal <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(leaderReplica) =&gt;</span><br><span class="line">          <span class="comment">// 获取对应的Log对象</span></span><br><span class="line">          <span class="keyword">val</span> log = leaderReplica.log.get</span><br><span class="line">          <span class="keyword">val</span> minIsr = log.config.minInSyncReplicas</span><br><span class="line">          <span class="keyword">val</span> inSyncSize = inSyncReplicas.size</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Avoid writing to leader if there are not enough insync replicas to make it safe</span></span><br><span class="line">          <span class="comment">// 如果ack设置为-1,isr数小于设置的min.isr时,会向producer抛出异常</span></span><br><span class="line">          <span class="keyword">if</span> (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotEnoughReplicasException</span>(<span class="string">s"The size of the current ISR <span class="subst">$&#123;inSyncReplicas.map(_.brokerId)&#125;</span> "</span> +</span><br><span class="line">              <span class="string">s"is insufficient to satisfy the min.isr requirement of <span class="subst">$minIsr</span> for partition <span class="subst">$topicPartition</span>"</span>)</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// 向副本对应的log追加相应的数据</span></span><br><span class="line">          <span class="keyword">val</span> info = log.appendAsLeader(records, leaderEpoch = <span class="keyword">this</span>.leaderEpoch, isFromClient)</span><br><span class="line">          <span class="comment">// probably unblock some follower fetch requests since log end offset has been updated</span></span><br><span class="line">          replicaManager.tryCompleteDelayedFetch(<span class="type">TopicPartitionOperationKey</span>(<span class="keyword">this</span>.topic, <span class="keyword">this</span>.partitionId))</span><br><span class="line">          <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">          <span class="comment">// 判断是否需要增加HW(追加日志后会进行一次判断)</span></span><br><span class="line">          (info, maybeIncrementLeaderHW(leaderReplica))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          <span class="comment">// leader不在本台机器上</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NotLeaderForPartitionException</span>(<span class="string">"Leader not local for partition %s on broker %d"</span></span><br><span class="line">            .format(topicPartition, localBrokerId))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">    <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line"></span><br><span class="line">    info</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h2><h3 id="Log对象"><a href="#Log对象" class="headerlink" title="Log对象"></a>Log对象</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">每个<span class="type">Replica</span>都会对应一个<span class="type">Log</span>对象,<span class="type">Log</span>对象是管理当前分区的一个单位</span><br><span class="line">它会包含这个分区的所有<span class="type">Segment</span>文件(包括索引,时间戳索引文件)</span><br><span class="line">提供增删查方法</span><br><span class="line"></span><br><span class="line">nextOffsetMetadata: 下一个偏移量元数据,包括activeSegment的下一条消息的偏移量,该activeSegment的基准偏移量及日志分段的大小</span><br><span class="line">activeSegment: <span class="type">Log</span>管理segments中最新segment,一个<span class="type">Log</span>只会有一个activeSegment,其他的segment已经持久化到磁盘了</span><br><span class="line">logEndOffset: 下一条消息的offset,取自nextOffsetMetadata的offset</span><br><span class="line"></span><br><span class="line"><span class="comment">// 声明为volatile,如果该值被修改,其他使用此变量的线程就可以立刻见到变化后的值,在生产和消费都会使用到这个值</span></span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> nextOffsetMetadata: <span class="type">LogOffsetMetadata</span> = _</span><br><span class="line"><span class="comment">// 下一个偏移量元数据</span></span><br><span class="line"><span class="comment">// 第一个参数: 下一条消息的偏移量</span></span><br><span class="line"><span class="comment">// 第二个参数: 日志分段的基准偏移量</span></span><br><span class="line"><span class="comment">// 第三个参数: 日志分段大小</span></span><br><span class="line">nextOffsetMetadata = <span class="keyword">new</span> <span class="type">LogOffsetMetadata</span>(nextOffset, activeSegment.baseOffset, activeSegment.size)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 只会有一个活动的日志分段</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">activeSegment</span> </span>= segments.lastEntry.getValue</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下一条消息的offset,从nextOffsetMetadata获取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logEndOffset</span></span>: <span class="type">Long</span> = nextOffsetMetadata.messageOffset</span><br></pre></td></tr></table></figure>
<h4 id="日志写入"><a href="#日志写入" class="headerlink" title="日志写入"></a>日志写入</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">analyzeAndValidateRecords(): 对这批要写入的消息进行检测,检查消息的大小以及校验</span><br><span class="line">trimInvalidBytes(): 删除无效消息</span><br><span class="line"><span class="type">LogValidator</span>.validateMessagesAndAssignOffsets(): 设置相应的offset和timestrap</span><br><span class="line">maybeRoll(): 判断是否需要新建一个segment,如果当前segment放不下这批消息的话,需要新建</span><br><span class="line">segment.append(): 向segment添加信息</span><br><span class="line">updateLogEndOffset(): 更新<span class="type">LEO</span></span><br><span class="line">flush(): 刷新磁盘</span><br><span class="line"></span><br><span class="line">时间戳记录有两种</span><br><span class="line">    <span class="type">CreateTime</span>: 默认,创建时间</span><br><span class="line">    <span class="type">LogAppendTime</span>: 添加时间</span><br><span class="line"></span><br><span class="line"><span class="comment">// 向activeSegment追加log,必要的情况下,滚动创建新的segment</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(records: <span class="type">MemoryRecords</span>, isFromClient: <span class="type">Boolean</span>, assignOffsets: <span class="type">Boolean</span>, leaderEpoch: <span class="type">Int</span>): <span class="type">LogAppendInfo</span> = &#123;</span><br><span class="line">    maybeHandleIOException(<span class="string">s"Error while appending records to <span class="subst">$topicPartition</span> in dir <span class="subst">$&#123;dir.getParent&#125;</span>"</span>) &#123;</span><br><span class="line">      <span class="comment">// 返回这批消息的概要信息,并对其进行校验</span></span><br><span class="line">      <span class="keyword">val</span> appendInfo = analyzeAndValidateRecords(records, isFromClient = isFromClient)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// return if we have no valid messages or if this is a duplicate of the last appended entry</span></span><br><span class="line">      <span class="keyword">if</span> (appendInfo.shallowCount == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> appendInfo</span><br><span class="line"></span><br><span class="line">      <span class="comment">// trim any invalid bytes or partial messages before appending it to the on-disk log</span></span><br><span class="line">      <span class="comment">// 删除无效信息</span></span><br><span class="line">      <span class="keyword">var</span> validRecords = trimInvalidBytes(records, appendInfo)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// they are valid, insert them in the log</span></span><br><span class="line">      lock synchronized &#123;</span><br><span class="line">        checkIfMemoryMappedBufferClosed()</span><br><span class="line">        <span class="keyword">if</span> (assignOffsets) &#123;</span><br><span class="line">          <span class="comment">// assign offsets to the message set</span></span><br><span class="line">          <span class="comment">// 计算这个消息集的起始offset,对offset的操作是一个原子操作</span></span><br><span class="line">          <span class="keyword">val</span> offset = <span class="keyword">new</span> <span class="type">LongRef</span>(nextOffsetMetadata.messageOffset)</span><br><span class="line">          <span class="comment">// 作为消息集的第一个offset</span></span><br><span class="line">          appendInfo.firstOffset = <span class="type">Some</span>(offset.value)</span><br><span class="line">          <span class="comment">// 设置时间戳以server收到的时间戳为准</span></span><br><span class="line">          <span class="keyword">val</span> now = time.milliseconds</span><br><span class="line">          <span class="comment">// 验证消息,并为每条record设置相应的offset和timestrap</span></span><br><span class="line">          <span class="keyword">val</span> validateAndOffsetAssignResult = <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">LogValidator</span>.validateMessagesAndAssignOffsets(validRecords,</span><br><span class="line">              offset,</span><br><span class="line">              time,</span><br><span class="line">              now,</span><br><span class="line">              appendInfo.sourceCodec,</span><br><span class="line">              appendInfo.targetCodec,</span><br><span class="line">              config.compact,</span><br><span class="line">              config.messageFormatVersion.recordVersion.value,</span><br><span class="line">              config.messageTimestampType,</span><br><span class="line">              config.messageTimestampDifferenceMaxMs,</span><br><span class="line">              leaderEpoch,</span><br><span class="line">              isFromClient)</span><br><span class="line">          &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">s"Error validating messages while appending to log <span class="subst">$name</span>"</span>, e)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 返回已经计算好的offset和timestrap的MemoryRecord</span></span><br><span class="line">          validRecords = validateAndOffsetAssignResult.validatedRecords</span><br><span class="line">          appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp</span><br><span class="line">          appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp</span><br><span class="line">          <span class="comment">// 最后一条消息的offset</span></span><br><span class="line">          appendInfo.lastOffset = offset.value - <span class="number">1</span></span><br><span class="line">          appendInfo.recordConversionStats = validateAndOffsetAssignResult.recordConversionStats</span><br><span class="line">          <span class="keyword">if</span> (config.messageTimestampType == <span class="type">TimestampType</span>.<span class="type">LOG_APPEND_TIME</span>)</span><br><span class="line">            appendInfo.logAppendTime = now</span><br><span class="line"></span><br><span class="line">          <span class="comment">// re-validate message sizes if there's a possibility that they have changed (due to re-compression or message</span></span><br><span class="line">          <span class="comment">// format conversion)</span></span><br><span class="line">          <span class="comment">// 更新metrics记录</span></span><br><span class="line">          <span class="keyword">if</span> (validateAndOffsetAssignResult.messageSizeMaybeChanged) &#123;</span><br><span class="line">            <span class="keyword">for</span> (batch &lt;- validRecords.batches.asScala) &#123;</span><br><span class="line">              <span class="keyword">if</span> (batch.sizeInBytes &gt; config.maxMessageSize) &#123;</span><br><span class="line">                <span class="comment">// we record the original message set size instead of the trimmed size</span></span><br><span class="line">                <span class="comment">// to be consistent with pre-compression bytesRejectedRate recording</span></span><br><span class="line">                brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class="line">                brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RecordTooLargeException</span>(<span class="string">s"Message batch size is <span class="subst">$&#123;batch.sizeInBytes&#125;</span> bytes in append to"</span> +</span><br><span class="line">                  <span class="string">s"partition <span class="subst">$topicPartition</span> which exceeds the maximum configured size of <span class="subst">$&#123;config.maxMessageSize&#125;</span>."</span>)</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// we are taking the offsets we are given</span></span><br><span class="line">          <span class="keyword">if</span> (!appendInfo.offsetsMonotonic)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">OffsetsOutOfOrderException</span>(<span class="string">s"Out of order offsets found in append to <span class="subst">$topicPartition</span>: "</span> +</span><br><span class="line">                                                 records.records.asScala.map(_.offset))</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (appendInfo.firstOrLastOffsetOfFirstBatch &lt; nextOffsetMetadata.messageOffset) &#123;</span><br><span class="line">            <span class="comment">// we may still be able to recover if the log is empty</span></span><br><span class="line">            <span class="comment">// one example: fetching from log start offset on the leader which is not batch aligned,</span></span><br><span class="line">            <span class="comment">// which may happen as a result of AdminClient#deleteRecords()</span></span><br><span class="line">            <span class="keyword">val</span> firstOffset = appendInfo.firstOffset <span class="keyword">match</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">Some</span>(offset) =&gt; offset</span><br><span class="line">              <span class="keyword">case</span> <span class="type">None</span> =&gt; records.batches.asScala.head.baseOffset()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> firstOrLast = <span class="keyword">if</span> (appendInfo.firstOffset.isDefined) <span class="string">"First offset"</span> <span class="keyword">else</span> <span class="string">"Last offset of the first batch"</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnexpectedAppendOffsetException</span>(</span><br><span class="line">              <span class="string">s"Unexpected offset in append to <span class="subst">$topicPartition</span>. <span class="subst">$firstOrLast</span> "</span> +</span><br><span class="line">              <span class="string">s"<span class="subst">$&#123;appendInfo.firstOrLastOffsetOfFirstBatch&#125;</span> is less than the next offset <span class="subst">$&#123;nextOffsetMetadata.messageOffset&#125;</span>. "</span> +</span><br><span class="line">              <span class="string">s"First 10 offsets in append: <span class="subst">$&#123;records.records.asScala.take(10).map(_.offset)&#125;</span>, last offset in"</span> +</span><br><span class="line">              <span class="string">s" append: <span class="subst">$&#123;appendInfo.lastOffset&#125;</span>. Log start offset = <span class="subst">$logStartOffset</span>"</span>,</span><br><span class="line">              firstOffset, appendInfo.lastOffset)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the epoch cache with the epoch stamped onto the message by the leader</span></span><br><span class="line">        validRecords.batches.asScala.foreach &#123; batch =&gt;</span><br><span class="line">          <span class="keyword">if</span> (batch.magic &gt;= <span class="type">RecordBatch</span>.<span class="type">MAGIC_VALUE_V2</span>)</span><br><span class="line">            _leaderEpochCache.assign(batch.partitionLeaderEpoch, batch.baseOffset)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// check messages set size may be exceed config.segmentSize</span></span><br><span class="line">        <span class="keyword">if</span> (validRecords.sizeInBytes &gt; config.segmentSize) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RecordBatchTooLargeException</span>(<span class="string">s"Message batch size is <span class="subst">$&#123;validRecords.sizeInBytes&#125;</span> bytes in append "</span> +</span><br><span class="line">            <span class="string">s"to partition <span class="subst">$topicPartition</span>, which exceeds the maximum configured segment size of <span class="subst">$&#123;config.segmentSize&#125;</span>."</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// now that we have valid records, offsets assigned, and timestamps updated, we need to</span></span><br><span class="line">        <span class="comment">// validate the idempotent/transactional state of the producers and collect some metadata</span></span><br><span class="line">        <span class="keyword">val</span> (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)</span><br><span class="line">        maybeDuplicate.foreach &#123; duplicate =&gt;</span><br><span class="line">          appendInfo.firstOffset = <span class="type">Some</span>(duplicate.firstOffset)</span><br><span class="line">          appendInfo.lastOffset = duplicate.lastOffset</span><br><span class="line">          appendInfo.logAppendTime = duplicate.timestamp</span><br><span class="line">          appendInfo.logStartOffset = logStartOffset</span><br><span class="line">          <span class="keyword">return</span> appendInfo</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// maybe roll the log if this segment is full</span></span><br><span class="line">        <span class="comment">// 如果当前segment满了,需要重新创建一个segment</span></span><br><span class="line">        <span class="keyword">val</span> segment = maybeRoll(validRecords.sizeInBytes, appendInfo)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> logOffsetMetadata = <span class="type">LogOffsetMetadata</span>(</span><br><span class="line">          messageOffset = appendInfo.firstOrLastOffsetOfFirstBatch,</span><br><span class="line">          segmentBaseOffset = segment.baseOffset,</span><br><span class="line">          relativePositionInSegment = segment.size)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 追加消息到当前segment</span></span><br><span class="line">        segment.append(largestOffset = appendInfo.lastOffset,</span><br><span class="line">          largestTimestamp = appendInfo.maxTimestamp,</span><br><span class="line">          shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,</span><br><span class="line">          records = validRecords)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the producer state</span></span><br><span class="line">        <span class="keyword">for</span> ((_, producerAppendInfo) &lt;- updatedProducers) &#123;</span><br><span class="line">          producerAppendInfo.maybeCacheTxnFirstOffsetMetadata(logOffsetMetadata)</span><br><span class="line">          producerStateManager.update(producerAppendInfo)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the transaction index with the true last stable offset. The last offset visible</span></span><br><span class="line">        <span class="comment">// to consumers using READ_COMMITTED will be limited by this value and the high watermark.</span></span><br><span class="line">        <span class="keyword">for</span> (completedTxn &lt;- completedTxns) &#123;</span><br><span class="line">          <span class="keyword">val</span> lastStableOffset = producerStateManager.completeTxn(completedTxn)</span><br><span class="line">          segment.updateTxnIndex(completedTxn, lastStableOffset)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// always update the last producer id map offset so that the snapshot reflects the current offset</span></span><br><span class="line">        <span class="comment">// even if there isn't any idempotent data being written</span></span><br><span class="line">        producerStateManager.updateMapEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// increment the log end offset</span></span><br><span class="line">        <span class="comment">// 修改最新的next_offset</span></span><br><span class="line">        updateLogEndOffset(appendInfo.lastOffset + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// update the first unstable offset (which is used to compute LSO)</span></span><br><span class="line">        updateFirstUnstableOffset()</span><br><span class="line"></span><br><span class="line">        trace(<span class="string">s"Appended message set with last offset: <span class="subst">$&#123;appendInfo.lastOffset&#125;</span>, "</span> +</span><br><span class="line">          <span class="string">s"first offset: <span class="subst">$&#123;appendInfo.firstOffset&#125;</span>, "</span> +</span><br><span class="line">          <span class="string">s"next offset: <span class="subst">$&#123;nextOffsetMetadata.messageOffset&#125;</span>, "</span> +</span><br><span class="line">          <span class="string">s"and messages: <span class="subst">$validRecords</span>"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 满足条件的话,刷新磁盘</span></span><br><span class="line">        <span class="keyword">if</span> (unflushedMessages &gt;= config.flushInterval)</span><br><span class="line">          flush()</span><br><span class="line"></span><br><span class="line">        appendInfo</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h4 id="日志分段"><a href="#日志分段" class="headerlink" title="日志分段"></a>日志分段</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">// 判断是否需要创建日志分段,如果不需要,就返回当前分段,需要则返回新创建的日志分段</span><br><span class="line">private def maybeRoll(messagesSize: Int, appendInfo: LogAppendInfo): LogSegment = &#123;</span><br><span class="line">    // 最新日志分段(活跃日志分段)</span><br><span class="line">    val segment = activeSegment</span><br><span class="line">    val now = time.milliseconds</span><br><span class="line"></span><br><span class="line">    val maxTimestampInMessages = appendInfo.maxTimestamp</span><br><span class="line">    val maxOffsetInMessages = appendInfo.lastOffset</span><br><span class="line"></span><br><span class="line">    if (segment.shouldRoll(RollParams(config, appendInfo, messagesSize, now))) &#123;</span><br><span class="line">      debug(s&quot;Rolling new log segment (log_size = $&#123;segment.size&#125;/$&#123;config.segmentSize&#125;&#125;, &quot; +</span><br><span class="line">        s&quot;offset_index_size = $&#123;segment.offsetIndex.entries&#125;/$&#123;segment.offsetIndex.maxEntries&#125;, &quot; +</span><br><span class="line">        s&quot;time_index_size = $&#123;segment.timeIndex.entries&#125;/$&#123;segment.timeIndex.maxEntries&#125;, &quot; +</span><br><span class="line">        s&quot;inactive_time_ms = $&#123;segment.timeWaitedForRoll(now, maxTimestampInMessages)&#125;/$&#123;config.segmentMs - segment.rollJitterMs&#125;).&quot;)</span><br><span class="line">      appendInfo.firstOffset match &#123;</span><br><span class="line">        // 创建新的日志分段</span><br><span class="line">        case Some(firstOffset) =&gt; roll(firstOffset)</span><br><span class="line">        case None =&gt; roll(maxOffsetInMessages - Integer.MAX_VALUE)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      // 使用当前的日志分段</span><br><span class="line">      segment</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// LogSegment</span><br><span class="line">def shouldRoll(rollParams: RollParams): Boolean = &#123;</span><br><span class="line">  // 距离上次日志分段是否达到了阈值</span><br><span class="line">  val reachedRollMs = timeWaitedForRoll(rollParams.now, rollParams.maxTimestampInMessages) &gt; rollParams.maxSegmentMs - rollJitterMs</span><br><span class="line">  // 1.文件满了,不足以放下这么大的messageSet</span><br><span class="line">  // 2.文件有数据,到了分段的阈值</span><br><span class="line">  // 3.索引文件满了</span><br><span class="line">  // 4.时间索引文件满了</span><br><span class="line">  // 5.最大offset,其相对偏移量超过了正整数的阈值</span><br><span class="line">  size &gt; rollParams.maxSegmentBytes - rollParams.messagesSize ||</span><br><span class="line">    (size &gt; 0 &amp;&amp; reachedRollMs) ||</span><br><span class="line">    offsetIndex.isFull || timeIndex.isFull || !canConvertToRelativeOffset(rollParams.maxOffsetInMessages)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 滚动创建日志,并添加到日志管理的映射表中</span><br><span class="line">def roll(expectedNextOffset: Long = 0): LogSegment = &#123;</span><br><span class="line">    maybeHandleIOException(s&quot;Error while rolling log segment for $topicPartition in dir $&#123;dir.getParent&#125;&quot;) &#123;</span><br><span class="line">      val start = time.hiResClockMs()</span><br><span class="line">      lock synchronized &#123;</span><br><span class="line">        checkIfMemoryMappedBufferClosed()</span><br><span class="line">        // 选择最新的offset作为基准偏移量</span><br><span class="line">        val newOffset = math.max(expectedNextOffset, logEndOffset)</span><br><span class="line">        // 创建数据文件</span><br><span class="line">        val logFile = Log.logFile(dir, newOffset)</span><br><span class="line">        // 创建offset索引文件</span><br><span class="line">        val offsetIdxFile = offsetIndexFile(dir, newOffset)</span><br><span class="line">        // 创建时间索引文件</span><br><span class="line">        val timeIdxFile = timeIndexFile(dir, newOffset)</span><br><span class="line">        val txnIdxFile = transactionIndexFile(dir, newOffset)</span><br><span class="line">        for (file &lt;- List(logFile, offsetIdxFile, timeIdxFile, txnIdxFile) if file.exists) &#123;</span><br><span class="line">          warn(s&quot;Newly rolled segment file $&#123;file.getAbsolutePath&#125; already exists; deleting it first&quot;)</span><br><span class="line">          Files.delete(file.toPath)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Option(segments.lastEntry).foreach(_.getValue.onBecomeInactiveSegment())</span><br><span class="line"></span><br><span class="line">        producerStateManager.updateMapEndOffset(newOffset)</span><br><span class="line">        producerStateManager.takeSnapshot()</span><br><span class="line"></span><br><span class="line">        // 创建一个segment对象</span><br><span class="line">        val segment = LogSegment.open(dir,</span><br><span class="line">          baseOffset = newOffset,</span><br><span class="line">          config,</span><br><span class="line">          time = time,</span><br><span class="line">          fileAlreadyExists = false,</span><br><span class="line">          initFileSize = initFileSize,</span><br><span class="line">          preallocate = config.preallocate)</span><br><span class="line">        // 添加到日志管理中</span><br><span class="line">        val prev = addSegment(segment)</span><br><span class="line">        if (prev != null)</span><br><span class="line">          throw new KafkaException(s&quot;Trying to roll a new log segment for topic partition $topicPartition with &quot; +</span><br><span class="line">            s&quot;start offset $newOffset while it already exists.&quot;)</span><br><span class="line">        // 更新offset</span><br><span class="line">        updateLogEndOffset(nextOffsetMetadata.messageOffset)</span><br><span class="line">        // schedule an asynchronous flush of the old segment</span><br><span class="line">        scheduler.schedule(&quot;flush-log&quot;, () =&gt; flush(newOffset), delay = 0L)</span><br><span class="line"></span><br><span class="line">        info(s&quot;Rolled new log segment at offset $newOffset in $&#123;time.hiResClockMs() - start&#125; ms.&quot;)</span><br><span class="line"></span><br><span class="line">        segment</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="LogSegment对象"><a href="#LogSegment对象" class="headerlink" title="LogSegment对象"></a>LogSegment对象</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">真正的日志写入,在LogSegment的append()方法中完成</span><br><span class="line">它会跟Kafka最底层的文件通道,mmap打交道</span><br><span class="line"></span><br><span class="line">// 在指定offset处追加msgs,需要的情况下追加相应的索引</span><br><span class="line">@nonthreadsafe</span><br><span class="line">def append(largestOffset: Long,</span><br><span class="line">             largestTimestamp: Long,</span><br><span class="line">             shallowOffsetOfMaxTimestamp: Long,</span><br><span class="line">             records: MemoryRecords): Unit = &#123;</span><br><span class="line">    if (records.sizeInBytes &gt; 0) &#123;</span><br><span class="line">      trace(s&quot;Inserting $&#123;records.sizeInBytes&#125; bytes at end offset $largestOffset at position $&#123;log.sizeInBytes&#125; &quot; +</span><br><span class="line">            s&quot;with largest timestamp $largestTimestamp at shallow offset $shallowOffsetOfMaxTimestamp&quot;)</span><br><span class="line">      val physicalPosition = log.sizeInBytes()</span><br><span class="line">      if (physicalPosition == 0)</span><br><span class="line">        rollingBasedTimestamp = Some(largestTimestamp)</span><br><span class="line"></span><br><span class="line">      ensureOffsetInRange(largestOffset)</span><br><span class="line"></span><br><span class="line">      // 追加到数据文件</span><br><span class="line">      val appendedBytes = log.append(records)</span><br><span class="line">      trace(s&quot;Appended $appendedBytes to $&#123;log.file&#125; at end offset $largestOffset&quot;)</span><br><span class="line">      // Update the in memory max timestamp and corresponding offset.</span><br><span class="line">      if (largestTimestamp &gt; maxTimestampSoFar) &#123;</span><br><span class="line">        maxTimestampSoFar = largestTimestamp</span><br><span class="line">        offsetOfMaxTimestamp = shallowOffsetOfMaxTimestamp</span><br><span class="line">      &#125;</span><br><span class="line">      // 判断是否需要追加索引(数据每次都会添加到数据文件中,但不是每次都会添加索引的,间隔indexIntervalBytes 大小才会写入一个索引文件)</span><br><span class="line">      if (bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123;</span><br><span class="line">        // 添加索引</span><br><span class="line">        offsetIndex.append(largestOffset, physicalPosition)</span><br><span class="line">        timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp)</span><br><span class="line">        bytesSinceLastIndexEntry = 0</span><br><span class="line">      &#125;</span><br><span class="line">      bytesSinceLastIndexEntry += records.sizeInBytes</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="索引文件"><a href="#索引文件" class="headerlink" title="索引文件"></a>索引文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">offsetIndex以及timeIndex</span><br><span class="line"></span><br><span class="line">offsetIndex</span><br><span class="line">    采用绝对偏移量+相对偏移量的方式进行存储,每个segment最开始的绝对偏移量也是其基准偏移量</span><br><span class="line">    数据文件每隔一定的大小创建一个索引条目,而不是每条消息会创建索引条目,通过index.interval.bytes来配置</span><br><span class="line">        默认4096,4KB</span><br><span class="line"></span><br><span class="line">好处:</span><br><span class="line">    索引条目稀疏</span><br><span class="line">    索引的相对偏移量占据4个字节,绝对偏移量占据8个字节,物理位置4个字节</span><br><span class="line">        使用相对索引可以将每条索引条目的大小从12字节减少到8字节</span><br><span class="line">    因为偏移量有序的,再读取数据时,可以按照二分查找的方式去快速定位偏移量的位置</span><br><span class="line">    这样的稀疏索引是可以完全放到内存中,加快偏移量的查找</span><br></pre></td></tr></table></figure>
  </div>
  <footer class="article-footer">
    
  <div class="cc">
    <a href="http://creativecommons.org/licenses/by-sa/4.0/deed.z" target="_blank" title="署名-相同方式共享">
      <img src="/images/cc/cc.png">
      
          <img src="/images/cc/by.png">
        
          <img src="/images/cc/sa.png">
      
      <span>
        本作品采用知识共享 署名-相同方式共享 4.0 国际许可协议进行许可。
      </span>
    </a>
  </div>


    

  </footer>
</article>







          <div class="main-footer">
  
    © 2020 BlackC - Powered by <a href="http://hexo.io" target="_blank">Hexo</a> - Theme <a href="https://github.com/denjones/hexo-theme-chan" target="_blank">Chan</a>
  
</div>

      
        </div>
      
    </div>
  </div>
  <script src="//apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>

  <link rel="stylesheet" href="/PhotoSwipe/photoswipe.css">
  <link rel="stylesheet" href="/PhotoSwipe/default-skin/default-skin.css">

  <!-- Root element of PhotoSwipe. Must have class pswp. -->
  <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
             It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

      <!-- Container that holds slides.
                PhotoSwipe keeps only 3 of them in the DOM to save memory.
                Don't modify these 3 pswp__item elements, data is added later on. -->
      <div class="pswp__container">
        <div class="pswp__item"></div>
        <div class="pswp__item"></div>
        <div class="pswp__item"></div>
      </div>

      <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
      <div class="pswp__ui pswp__ui--hidden">

        <div class="pswp__top-bar">

          <!--  Controls are self-explanatory. Order can be changed. -->

          <div class="pswp__counter"></div>

          <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

          <button class="pswp__button pswp__button--share" title="Share"></button>

          <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

          <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

          <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
          <!-- element will get class pswp__preloader--active when preloader is running -->
          <div class="pswp__preloader">
            <div class="pswp__preloader__icn">
              <div class="pswp__preloader__cut">
                <div class="pswp__preloader__donut"></div>
              </div>
            </div>
          </div>
        </div>

        <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
          <div class="pswp__share-tooltip"></div>
        </div>

        <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>

        <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

        <div class="pswp__caption">
          <div class="pswp__caption__center"></div>
        </div>
      </div>
    </div>
  </div>

  <script src="/PhotoSwipe/photoswipe.js"></script>
  <script src="/PhotoSwipe/photoswipe-ui-default.js"></script>


<script src="/perfect-scrollbar/js/min/perfect-scrollbar.min.js"></script>
<script src="/scripts/main.js"></script>

</body>
</html>
