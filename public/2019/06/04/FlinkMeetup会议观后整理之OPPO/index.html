<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;yoursite.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script><script src="/js/config.js"></script>
<meta name="description" content="对于4月份在深圳举行的FlinkMeetup峰会,做一些知识性总结,提升一下自己,OPPO篇其实张俊张老师已经在过往记忆上做过总结整理了-传送门,本文更多的是了解自己的不足">
<meta property="og:type" content="article">
<meta property="og:title" content="FlinkMeetup会议观后整理之OPPO">
<meta property="og:url" content="http://yoursite.com/2019/06/04/FlinkMeetup%E4%BC%9A%E8%AE%AE%E8%A7%82%E5%90%8E%E6%95%B4%E7%90%86%E4%B9%8BOPPO/index.html">
<meta property="og:site_name" content="BlackC">
<meta property="og:description" content="对于4月份在深圳举行的FlinkMeetup峰会,做一些知识性总结,提升一下自己,OPPO篇其实张俊张老师已经在过往记忆上做过总结整理了-传送门,本文更多的是了解自己的不足">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-06-04T00:59:01.000Z">
<meta property="article:modified_time" content="2021-03-21T12:33:13.846Z">
<meta property="article:author" content="X&amp;Z">
<meta property="article:tag" content="flink">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/2019/06/04/FlinkMeetup%E4%BC%9A%E8%AE%AE%E8%A7%82%E5%90%8E%E6%95%B4%E7%90%86%E4%B9%8BOPPO/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;06&#x2F;04&#x2F;FlinkMeetup%E4%BC%9A%E8%AE%AE%E8%A7%82%E5%90%8E%E6%95%B4%E7%90%86%E4%B9%8BOPPO&#x2F;&quot;,&quot;path&quot;:&quot;2019&#x2F;06&#x2F;04&#x2F;FlinkMeetup会议观后整理之OPPO&#x2F;&quot;,&quot;title&quot;:&quot;FlinkMeetup会议观后整理之OPPO&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>FlinkMeetup会议观后整理之OPPO | BlackC</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">BlackC</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="nav-number">1.</span> <span class="nav-text">主要内容</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81OPPO%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E7%9A%84%E6%BC%94%E8%BF%9B%E6%80%9D%E8%B7%AF"><span class="nav-number">2.</span> <span class="nav-text">一、OPPO实时数仓的演进思路</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-OPPO%E4%B8%9A%E5%8A%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E8%A7%84%E6%A8%A1"><span class="nav-number">2.1.</span> <span class="nav-text">1.OPPO业务与数据规模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-OPPO%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0"><span class="nav-number">2.2.</span> <span class="nav-text">2.OPPO数据中台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%9E%84%E5%BB%BAOPPO%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93"><span class="nav-number">2.3.</span> <span class="nav-text">3.构建OPPO离线数仓</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E6%95%B0%E4%BB%93%E5%AE%9E%E6%97%B6%E5%8C%96%E7%9A%84%E8%AF%89%E6%B1%82"><span class="nav-number">2.4.</span> <span class="nav-text">4.数仓实时化的诉求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E7%A6%BB%E7%BA%BF%E5%88%B0%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%B9%B3%E6%BB%91%E8%BF%81%E7%A7%BB"><span class="nav-number">2.5.</span> <span class="nav-text">5.离线到实现的平滑迁移</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E6%9E%84%E5%BB%BAOPPO%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93"><span class="nav-number">2.6.</span> <span class="nav-text">6.构建OPPO实时数仓</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E5%9F%BA%E4%BA%8EFlink-SQL%E7%9A%84%E6%89%A9%E5%B1%95%E5%B7%A5%E4%BD%9C"><span class="nav-number">3.</span> <span class="nav-text">二、基于Flink SQL的扩展工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Why-Flink-SQL"><span class="nav-number">3.1.</span> <span class="nav-text">1.Why Flink SQL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%9F%BA%E4%BA%8EWEB%E7%9A%84%E5%BC%80%E5%8F%91IDE"><span class="nav-number">3.2.</span> <span class="nav-text">2.基于WEB的开发IDE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-AthenaX-%E5%9F%BA%E4%BA%8EREST%E7%9A%84SQL%E7%AE%A1%E7%90%86%E5%99%A8"><span class="nav-number">3.3.</span> <span class="nav-text">3.AthenaX: 基于REST的SQL管理器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Flink-SQL%E6%B3%A8%E5%86%8C%E5%BA%93%E8%A1%A8%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="nav-number">3.4.</span> <span class="nav-text">4.Flink SQL注册库表的过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Flink-SQL%E5%AF%B9%E6%8E%A5%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="nav-number">3.5.</span> <span class="nav-text">5.Flink SQL对接外部数据源</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E5%AE%9E%E6%97%B6%E8%A1%A8-%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94"><span class="nav-number">3.6.</span> <span class="nav-text">6.实时表-维表关联</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-%E5%9F%BA%E4%BA%8EUDF%E7%9A%84%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94"><span class="nav-number">3.7.</span> <span class="nav-text">7.基于UDF的维表关联</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-%E5%9F%BA%E4%BA%8ESQL%E8%BD%AC%E6%8D%A2%E7%9A%84%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94"><span class="nav-number">3.8.</span> <span class="nav-text">8.基于SQL转换的维表关联</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E7%9A%84%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="nav-number">4.</span> <span class="nav-text">三、构建实时数仓的应用案例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%AE%9E%E6%97%B6ETL%E6%8B%86%E5%88%86"><span class="nav-number">4.1.</span> <span class="nav-text">1.实时ETL拆分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%9E%E6%97%B6%E6%8C%87%E6%A0%87%E7%BB%9F%E8%AE%A1"><span class="nav-number">4.2.</span> <span class="nav-text">2.实时指标统计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E5%AE%9E%E6%97%B6%E6%A0%87%E7%AD%BE%E5%AF%BC%E5%85%A5"><span class="nav-number">4.3.</span> <span class="nav-text">3.实时标签导入</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">X&Z</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">251</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/04/FlinkMeetup%E4%BC%9A%E8%AE%AE%E8%A7%82%E5%90%8E%E6%95%B4%E7%90%86%E4%B9%8BOPPO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="X&Z">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="BlackC">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          FlinkMeetup会议观后整理之OPPO
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-06-04 08:59:01" itemprop="dateCreated datePublished" datetime="2019-06-04T08:59:01+08:00">2019-06-04</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-03-21 20:33:13" itemprop="dateModified" datetime="2021-03-21T20:33:13+08:00">2021-03-21</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>对于4月份在深圳举行的FlinkMeetup峰会,做一些知识性总结,提升一下自己,OPPO篇其实张俊张老师已经在过往记忆上做过总结整理了-<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/ZZaaN0ubQgLqFwTiySi8UQ">传送门</a>,本文更多的是了解自己的不足</p>
</blockquote>
<span id="more"></span>

<hr>
<h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><ul>
<li>OPPO实时数仓的演进思路</li>
<li>基于Flink SQL的扩展条件</li>
<li>构建实时数仓的应用案例</li>
<li>未来的思考和展望</li>
</ul>
<hr>
<h2 id="一、OPPO实时数仓的演进思路"><a href="#一、OPPO实时数仓的演进思路" class="headerlink" title="一、OPPO实时数仓的演进思路"></a>一、OPPO实时数仓的演进思路</h2><h3 id="1-OPPO业务与数据规模"><a href="#1-OPPO业务与数据规模" class="headerlink" title="1.OPPO业务与数据规模"></a>1.OPPO业务与数据规模</h3><p>OPPO基于Android定制了自己的ColorOS系统,日活跃用户超过2亿.围绕着ColorOS,OPPO构建了很多互联网应用,比如应用商店,浏览器,信息流等.用户在使用这些互联网应用的同时,也给OPPO积累了大量的数据.目前OPPO的总数据量超过100PB,日增数据量超过200TB—<strong>数据</strong>.</p>
<p>要支撑这么大的一个数据量,OPPO研发出一整套的数据系统与服务,并逐渐形成了自己的数据中台体系—<strong>数据中台</strong>.</p>
<h3 id="2-OPPO数据中台"><a href="#2-OPPO数据中台" class="headerlink" title="2.OPPO数据中台"></a>2.OPPO数据中台</h3><p>数据中台是什么?数据中台是指通过数据技术,对海量数据进行采集,计算,存储,加工,同时统一标准和口径.如果将数据看做原材料,那么数据中台就是加工坊.把它分成4个层次:</p>
<blockquote>
<p><strong>业务支撑</strong>: 应用商店,浏览器,广告等;生产,品质,销售等;手软,ColorOs,影像等;IOT厂商</p>
<p><strong>数据产品与服务</strong>: BI报表,用户洞察,内容标签,精准营销,舆情监测</p>
<p><strong>全域数据体系</strong>: ID-Mapping,用户标签,内容标签</p>
<p><strong>数据仓库</strong>: 原始层,明细层,汇总层,应用层</p>
<p><strong>统一工具体系</strong>: 数据接入,数据治理,数据开发,数据消费</p>
<p><strong>基础设施</strong>: 存储,计算</p>
</blockquote>
<ul>
<li>最下层是统一工具体系,涵盖了”接入-治理-开发-消费”全数据链路;</li>
<li>基于工具体系之上构建了数据仓库,划分成”原始层-明细层-汇总层-应用层”,这也是经典的数仓架构;</li>
<li>再往上就是全域的数据体系,什么是全域呢?就是把公司所有的业务数据全部打通,形成统一的数据资产,比如ID-Mapping,用户标签等;</li>
<li>最终,数据要能被业务用起来,需要场景驱动的数据产品与服务.</li>
</ul>
<p>以上就是OPPO数据中台的整个体系,而数据仓库在其中处于非常基础与核心的位置.</p>
<h3 id="3-构建OPPO离线数仓"><a href="#3-构建OPPO离线数仓" class="headerlink" title="3.构建OPPO离线数仓"></a>3.构建OPPO离线数仓</h3><p>构建过程: 首先,数据来源基本是手机,日志文件以及DB数据库,基于Apache NiFI打造高可用,高吞吐的接入系统,将数据统一落入HDFS,形成原始层;紧接着,基于Hive的小时级ETL与天级汇总Hive任务,分别负责计算生成明细层与汇总层;最后,应用层是基于OPPO内部研发的数据产品,主要是报表分析,用户画像以及接口服务.此外,中间的明细层还支持Presto的<strong>即席查询</strong>与<strong>自助取数</strong>.</p>
<h3 id="4-数仓实时化的诉求"><a href="#4-数仓实时化的诉求" class="headerlink" title="4.数仓实时化的诉求"></a>4.数仓实时化的诉求</h3><blockquote>
<p><strong>业务侧</strong></p>
</blockquote>
<ul>
<li>实时报表: 人群投放的到达率/曝光率/点击率</li>
<li>实时标签: 用户当前所在的商圈</li>
<li>实时接口: 用户最近下载某APP的时间</li>
</ul>
<blockquote>
<p><strong>平台侧</strong></p>
</blockquote>
<ul>
<li>调度任务: 凌晨0点大批量启动</li>
<li>标签导入: 全量导入耗费数小时</li>
<li>质量监控: 及时发现数据问题</li>
</ul>
<p>对于数仓实时化的诉求,大家通常都是从业务视角来看,但其实站在平台的角度,实时化也能带来切实的好处.首先,从业务侧来看,报表,标签,接口等都会有实时的应用场景;其次,对平台侧来说:第一,大量的批量任务都是从0点开始启动,都是通过T+1的方式去做数据处理,这会导致计算负载集中爆发,对集群的压力很大;第二,标签导入也属于一种T+1批量任务,每次全量导入都会耗费很长的时间;第三,数据质量的监控也必须是T+1的,导致没办法及时发现数据的一些问题.</p>
<h3 id="5-离线到实现的平滑迁移"><a href="#5-离线到实现的平滑迁移" class="headerlink" title="5.离线到实现的平滑迁移"></a>5.离线到实现的平滑迁移</h3><table>
    <tr>
        <th rowspan="4">小时/天级</th>
        <th rowspan="2">API</th>
        <th>编程接口</th>
        <th>SQL+UDF</th>
    </tr>
    <tr>
        <th>数仓抽象</th>
        <th>Table</th>
    </tr>
    <tr>
        <th rowspan="2">RunTime</th>
        <th>批量计算</th>
        <th>Hive</th>
    </tr>
    <tr>
        <th>离线数据</th>
        <th>HDFS</th>
    </tr>
</table>
<table>
    <tr>
        <th rowspan="4">秒级/分级</th>
        <th rowspan="2">API</th>
        <th>编程接口</th>
        <th>SQL+UDF</th>
    </tr>
    <tr>
        <th>数仓抽象</th>
        <th>Table</th>
    </tr>
    <tr>
        <th rowspan="2">RunTime</th>
        <th>流式计算</th>
        <th>Flink</th>
    </tr>
    <tr>
        <th>实时数据</th>
        <th>Kafka</th>
    </tr>
</table>
无论是一个平台还是一个系统,都离不开上下两个层次的构成: 上层是API,是面向用户的编程抽象与接口;下层是RunTime,是面向内核的执行引擎.从离线到实时的迁移是平滑的,是什么意思?从API这层来看,数仓的抽象是Table,编程接口是SQL+UDF,离线数仓时代用户已经习惯了这样的API,迁移到实时数仓最好也能保持一致.而从RunTime层来看,计算引擎从Hive演进到了Flink,存储引擎从HDFS演进到了Kakfa.

<h3 id="6-构建OPPO实时数仓"><a href="#6-构建OPPO实时数仓" class="headerlink" title="6.构建OPPO实时数仓"></a>6.构建OPPO实时数仓</h3><p>构建过程: 与离线数仓基本相似,只是把Hive替换成Flink,把HDFS替换为Kafka.总体流程来看,基本模型是不变的,还是由原始层,明细层,汇总层,应用层的级联计算来构成.</p>
<p>核心问题: 如何基于Flink构建实时数仓.</p>
<hr>
<h2 id="二、基于Flink-SQL的扩展工作"><a href="#二、基于Flink-SQL的扩展工作" class="headerlink" title="二、基于Flink SQL的扩展工作"></a>二、基于Flink SQL的扩展工作</h2><h3 id="1-Why-Flink-SQL"><a href="#1-Why-Flink-SQL" class="headerlink" title="1.Why Flink SQL"></a>1.Why Flink SQL</h3><blockquote>
<p><strong>SQL</strong>: High-level Language</p>
</blockquote>
<ul>
<li>ANSI SQL + UDF</li>
<li>数据类型 + 内置函数</li>
<li>自定义Source/Sink</li>
<li>批流统一</li>
</ul>
<blockquote>
<p><strong>Table API</strong>: Declarative DSL</p>
</blockquote>
<blockquote>
<p><strong>DataStream/DataSet API</strong>: Core APIs</p>
</blockquote>
<blockquote>
<p><strong>Stateful Stream Processing</strong>: Low-level building block(streams,state,[event] time)</p>
</blockquote>
<ul>
<li>低延迟,高吞吐</li>
<li>高容错的状态管理</li>
<li>端到端exactly-once</li>
<li>Windows &amp; Event Time</li>
</ul>
<p>首先,为什么要用Flink SQL?上面展示了Flink框架的基本结构,最下面是Runtime,这个执行引擎我们认为最核心的优势是四个: 第一,低延迟,高吞吐;第二,端到端的Exactly-once;第三,可容错的状态管理;第四,Window &amp; Event time的支持.基于Runtime抽象出3个层次的API,SQL处于最上层.</p>
<p>Flink SQL API有哪些优势?也可以从四个方面去看: 第一,支持ANSI SQL的标准;第二, 支持丰富的数据类型与内置函数,包括常见的算术运算与统计聚合;第三,可自定义Source/Sink,基于此可以灵活地扩展上下游;第四,批流统一,同样的SQL,既可以跑离线也可以跑实时.</p>
<p><strong>ps:想了解下scala怎么实现获取Kafka消息,FlinkKafkaConsumer010?</strong></p>
<p>Flink SQL编程示例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="keyword">final</span> StreamTableEnvironment tblEnv = TableEnvironment.getTableEnvronment(env);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义与注册输入表</span></span><br><span class="line">tblEnv.connect(<span class="keyword">new</span> Kafka().version(<span class="string">&quot;0.10&quot;</span>)</span><br><span class="line">    .topic(<span class="string">&quot;input&quot;</span>).properties(kafkaParops).startFromGroupOffsets())</span><br><span class="line">    .withFormat(<span class="keyword">new</span> Avro().recordClass(SdkLog.class))</span><br><span class="line">    .withSchema(<span class="keyword">new</span> Schema().schema(TableSchema.fromTypeInfo(</span><br><span class="line">        AvroSchemaConverter.convertToTypeInfo(SdkLog.class))))</span><br><span class="line">    .inAppenddMode()</span><br><span class="line">    .registerTableSource(<span class="string">&quot;srcTable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义与注册输出表</span></span><br><span class="line">tblEnv.connect(<span class="keyword">new</span> Kafka().version(<span class="string">&quot;0.10&quot;</span>)</span><br><span class="line">    .topic(<span class="string">&quot;output&quot;</span>).properties(kafkaParops).startFromGroupOffsets())</span><br><span class="line">    .withFormat(<span class="keyword">new</span> Avro().recordClass(SdkLog.class))</span><br><span class="line">    .withSchema(<span class="keyword">new</span> Schema().schema(TableSchema.fromTypeInfo(</span><br><span class="line">        AvroSchemaConverter.convertToTypeInfo(SdkLog.class))))</span><br><span class="line">    .inAppenddMode()</span><br><span class="line">    .registerTableSource(<span class="string">&quot;dstTable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册UDF</span></span><br><span class="line">tblEnv.registerFunction(<span class="string">&quot;doubleFunc&quot;</span>, <span class="keyword">new</span> DoubleInt());</span><br><span class="line"><span class="comment">// 执行SQL</span></span><br><span class="line">tblEnv.sqlUpdate(<span class="string">&quot;INSERT INTO dstTable SELECT id,name,doubleFunc(age) FROM srcTable WHERE event[&#x27;eventTag&#x27;] = &#x27;10004&#x27;&quot;</span>);</span><br><span class="line"></span><br><span class="line">env.execute(<span class="string">&quot;Flink meetup demo&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>首先定义与注册输入/输出表,创建了2张Kafka的表,指定了Kafka版本,对应哪个topic;接下来注册UDF;最后才是执行真正的SQL.可以看到,为了执行SQL,需要做这么多编码工作,这不是我们希望暴露给用户的接口.</p>
<h3 id="2-基于WEB的开发IDE"><a href="#2-基于WEB的开发IDE" class="headerlink" title="2.基于WEB的开发IDE"></a>2.基于WEB的开发IDE</h3><p>前面提到过,数仓的抽象是Table,编程接口是SQL+UDF.对于用户来说,平台提供的编程界面应该是类似HUE的那种,有用过HUE做交互查询的应该很熟悉.左边是Table列表,右边是SQL编辑器,可以在上面直接写SQL,然后提交执行.要实现这样一种交互方式,Flink SQL默认是无法实现的,中间存在缺口,总结下来就两点:第一,元数据的管理,怎么去创建库表,怎么去上传UDF,使得之后在SQL中可直接引用;第二,SQL作业的管理,怎么去编译SQL,怎么去提交作业.</p>
<h3 id="3-AthenaX-基于REST的SQL管理器"><a href="#3-AthenaX-基于REST的SQL管理器" class="headerlink" title="3.AthenaX: 基于REST的SQL管理器"></a>3.AthenaX: 基于REST的SQL管理器</h3><p>AthenaX可以看作一个基于REST的SQL管理器,它是怎么实现SQL作业与元数据管理的呢?</p>
<ul>
<li>对于SQL作业提交,AthenaX中有一个Job的抽象,封装了要执行的SQL以及作业资源等信息.所有的Job由一个JobStore来托管,它定期跟YARN当中处于Running的App做一个匹配.如果不一致,就会向YARN提交对应的Job.</li>
<li>对于元数据管理,核心的问题是如何将外部创建的库表注入Flink,使得SQL中可以识别到.实际上,Flink本身就预留了与外部元数据对接的能力,分别提供了ExternalCatalog和ExternalCatalogTable这两个抽象.AthenaX在此基础上再封装出一个TableCatalog,在接口层面做了一定的扩展.在提交SQL作业的阶段,AthenaX会自动将TableCatalog注册到Flink,再调用Flink SQL的接口将SQL编译为Flink的可执行单元JobGraph,并最终提交到YARN生成新的App.</li>
</ul>
<p>AthenaX虽然定义好了TableCatalog接口,但并没有提供可直接使用的实现.那么,我们怎么来实现,以便对接到我们已有的元数据系统呢?</p>
<h3 id="4-Flink-SQL注册库表的过程"><a href="#4-Flink-SQL注册库表的过程" class="headerlink" title="4.Flink SQL注册库表的过程"></a>4.Flink SQL注册库表的过程</h3><p>首先,我们的搞清楚Flink SQL内部是如何注册库表的.整个过程涉及到三个基本的抽象:TableDescriptor,TableFactory以及TableEnvironment.</p>
<p>TableDescriptor顾名思义,是对表的描述,它由三个子描述符构成:第一是Connector,描述数据的来源,比如Kafka,ES等;第二是Format,描述数据的格式,比如csv,json,avro等;第三是Schema,描述每个字段的名称与类型.</p>
<p>TableDescriptor有两个基本的实现</p>
<ul>
<li>ConnectTableDescriptor用于描述内部表,也就是编程方式创建的表.</li>
<li>ExternalCatalogTable用于描述外部表.</li>
</ul>
<p>有了TableDescriptor,接下来需要TableFactory根据描述信息来实例化Table.不同的描述信息需要不同的TableFactory来处理,Flink如何找到匹配的TableFactory实现呢?实际上,为了保证框架的可扩展性,Flink采用了JavaSPI机制来加载所有声明过的TableFactory,通过遍历的方式去寻找哪个TableFactory是匹配该TableDescriptor的.TableDescriptor在传递给TableFactory前,被转换成一个map,所有的描述信息都用key-value的形式来表达.TableFactory定义了两个用于过滤匹配的方法,一个是requiredContext(),用于检测某些特定的key的value是否匹配,比如connector.type是否为kafka;另一个是supportedProperties(),用于检测key是否能识别,如果出现不识别的key,说明无法匹配.</p>
<p>匹配到了正确的TableFactory,接下来就是创建真正的Table,然后将其通过TableEnvironment注册.最终注册成功的Table,才能在SQL中引用.</p>
<h3 id="5-Flink-SQL对接外部数据源"><a href="#5-Flink-SQL对接外部数据源" class="headerlink" title="5.Flink SQL对接外部数据源"></a>5.Flink SQL对接外部数据源</h3><p>搞清楚了Flink SQL注册库表的过程,给我们带来这样一个思路:如果外部元数据创建的表也能被转换成TableFactory可识别的map,那么就能被无缝地注册到TableEnvironment.基于这个思路,我们实现了Flink SQL与已有元数据中心的对接.</p>
<p>通过元数据中心创建的表,都会将元数据信息存储到MySQL,我们用一张表来记录Table的基本信息,然后另外三张表分别记录Connector,Format,Schema转换成key-value后的描述信息.之所以拆开成三张表,是为了能够能独立的更新这三种描述信息.接下来是定制实现的ExternalCatalog,能够读取MySQL这四张表,并转换成map结构.</p>
<h3 id="6-实时表-维表关联"><a href="#6-实时表-维表关联" class="headerlink" title="6.实时表-维表关联"></a>6.实时表-维表关联</h3><p>到目前为止,我们的平台已经具备了元数据管理与SQL作业管理的能力,但是要真正开放给用户使用,还有一点基本特性存在缺失.通过我们去构建数仓,星型模型是无法避免的.这里有一个比较简单的案例:中间的事实表记录了广告点击流,周边是关于用户,广告,产品,渠道的维度表.</p>
<p>假定我们有一个SQL分析,需要将点击流表与用户维表进行关联,这个目前在Flink SQL中应该怎么实现?我们有两种实现方式,一个基于UDF,一个基于SQL转换.</p>
<h3 id="7-基于UDF的维表关联"><a href="#7-基于UDF的维表关联" class="headerlink" title="7.基于UDF的维表关联"></a>7.基于UDF的维表关联</h3><p>首先是基于UDF的实现,需要用户将原始SQL改写成带UDF调用的SQL,这里是userDimFunc,UserDimFunc继承了Flink SQL抽象的TableFunction,它是其中一种UDF类型,可以将任意一行数据转换成一行或多行数据.为了实现维表关联,在UDF初始化时需要从MySQL全量加载维表的数据,缓存在内存cache中.后续对每行数据的处理,TableFunction会调用eval()方法,在eval()中根据user_id去查找cache,从而实现关联.当然,这里是假定维表数据比较小,如果数据量很大,不适合全量的加载与缓存,这里不做展开了.</p>
<p>基于UDF的实现,对用户与平台来说都不太友好:用户需要写奇怪的SQL语句;平台需要为每个关联场景定制特定的UDF,维护成本太高.</p>
<h3 id="8-基于SQL转换的维表关联"><a href="#8-基于SQL转换的维表关联" class="headerlink" title="8.基于SQL转换的维表关联"></a>8.基于SQL转换的维表关联</h3><p>我们希望解决基于UDF实现所带来的问题,用户不需要改写原始SQL,平台不需要开发很多UDF.有一种思路是,是否可以在SQL交给Flink编译之前,加一层SQL的解析与改写,自动实现维表的关联?经过一定的技术调研与POC,我们发现是行得通的,所以称之为基于SQL转换的实现.</p>
<p>首先,增加的SQL解析是为了识别SQL中是否存在预先定义的维度表.一旦识别到维表,将触发SQL改写的流程,将红框标注的join语句改写成新的Table,这个Table怎么得到?我们知道,流计算领域近年来发展出”流表二象性”的理念,Flink也是该理念的践行者.这意味着,在Flink中Stream与Table之间是可以相互转换的.flatmap怎么实现维表关联?</p>
<p>Flink中对于Stream的flatmap操作,实际上是执行一个RichFlatmapFunction,每来一行数据就调用其flatmap()方法做转换.那么,我们可以定制一个RichFlatmapFunction,来实现维表数据的加载,缓存,查找以及关联,功能与基于UDF的TableFunction实现类似.</p>
<p>既然RichFlatmapFunction的实现逻辑与TableFunction相似,那为什么相比基于UDF的方式,这种实现能更加通用呢?核心的点在于多了一层SQL解析,可以将维表的信息获取出来(比如维表名,关联字段,select字段等),再封装成JoinContext传递给RichFlatmapFunction,使得它的表达能力就具备通用性了.</p>
<hr>
<h2 id="三、构建实时数仓的应用案例"><a href="#三、构建实时数仓的应用案例" class="headerlink" title="三、构建实时数仓的应用案例"></a>三、构建实时数仓的应用案例</h2><h3 id="1-实时ETL拆分"><a href="#1-实时ETL拆分" class="headerlink" title="1.实时ETL拆分"></a>1.实时ETL拆分</h3><p>这里是一个典型的实时ETL链路,从大表中拆分各业务对应的小表: 手机-&gt;NIFI-&gt;Kafka-&gt;ETL-&gt;Kafka/HDFS</p>
<p>OPPO的最大数据来源是手机端埋点,从手机APP过来的数据有一个特点,所有的数据是通过统一的几个通道上报过来.因为不可能每一次业务有新的埋点,都要去升级客户端,去增加新的通道.比如我们有个sdk_log通道,所有APP应用的埋点都往这个通道上报数据,导致这个通道对应的原始层表巨大,一天几十个TB.但实际上,每个业务只关心它自身的那部分数据,这就要求我们在原始层进行ETL拆分.</p>
<p>这个SQL逻辑比较简单,无非是根据某些业务字段做筛选,插入到不同的业务表中去.它的特点是,多行SQL最终合并成一个SQL提交给Flink执行.大家担心的是,包含了4个SQL,会不会对同一份数据重复读取4次?其实,在Flink编译SQL的阶段是会做一些优化的,因为最终指向的是同一个Kakfa topic,所以只会读取1次数据.</p>
<p>另外,同样的Flink SQL,我们同时用于离线与实时数仓的ETL拆分,分别落入HDFS与Kafka.Flink中本身支持写入HDFS的Sink,比如RollingFileSink.</p>
<h3 id="2-实时指标统计"><a href="#2-实时指标统计" class="headerlink" title="2.实时指标统计"></a>2.实时指标统计</h3><p>这里是一个典型的计算信息流CTR的这个案例,分别计算一定时间段内的曝光与点击次数,相除得到点击率导入MySQL,然后通过我们内部的报表系统来可视化.这个SQL的特点是它用到了窗口(Tumbling Window)以及子查询.</p>
<p><strong>窗口函数:</strong> TUMBLE函数</p>
<h3 id="3-实时标签导入"><a href="#3-实时标签导入" class="headerlink" title="3.实时标签导入"></a>3.实时标签导入</h3><p>这个SQL的特点是用了AggregateFunction,在5分钟的窗口内,我们只关心用户最新一次上报的经纬度.AggregateFunction是一种UDF类型,通常是用于聚合指标的统计,比如计算sum或者average.在这个示例中,由于我们只关心最新的经纬度,所以每次都替换老的数据即可.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/flink/" rel="tag"># flink</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/06/03/Flink%E8%AF%BB%E5%86%99Hbase%E4%B9%8B%E5%86%99/" rel="prev" title="Flink读写Hbase之写">
                  <i class="fa fa-chevron-left"></i> Flink读写Hbase之写
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2019/06/04/%E4%B8%80%E4%BA%9B%E5%87%BA%E7%8E%B0%E5%9C%A8%E4%B8%9A%E5%8A%A1%E9%9C%80%E6%B1%82%E4%B8%8A%E7%9A%84%E5%B0%8F%E7%82%B9%E5%AD%90/" rel="next" title="一些出现在业务需求上的小点子">
                  一些出现在业务需求上的小点子 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">X&Z</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  





</body>
</html>
